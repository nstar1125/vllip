{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/vllip/Mobile_SAM/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_5m_224 in registry with Mobile_SAM.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/workspace/vllip/Mobile_SAM/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_11m_224 in registry with Mobile_SAM.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/workspace/vllip/Mobile_SAM/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_224 in registry with Mobile_SAM.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/workspace/vllip/Mobile_SAM/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_384 in registry with Mobile_SAM.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/workspace/vllip/Mobile_SAM/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_512 in registry with Mobile_SAM.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_5m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_11m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_384 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_512 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n"
     ]
    }
   ],
   "source": [
    "# Grounding DINO\n",
    "import GroundingDINO.groundingdino.datasets.transforms as T\n",
    "from GroundingDINO.groundingdino.models import build_model\n",
    "from GroundingDINO.groundingdino.util.slconfig import SLConfig\n",
    "from GroundingDINO.groundingdino.util.utils import clean_state_dict, get_phrases_from_posmap\n",
    "\n",
    "# Segment anything\n",
    "from Mobile_SAM.build_sam import sam_model_registry\n",
    "from Mobile_SAM.utils.transforms import ResizeLongestSide\n",
    "\n",
    "#CLIP\n",
    "from models.backbones.backbone import CLIPViTFM, clip_backbone\n",
    "\n",
    "from cluster.Group import Cluster_GPU\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import utils as vutils\n",
    "import numpy as np\n",
    "import yaml\n",
    "from PIL import ImageFilter\n",
    "import random\n",
    "import json \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import builtins\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from utils import AverageMeter, ProgressMeter, to_log, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoWayTransform:\n",
    "    def __init__(self, base_transform_a,\n",
    "        base_transform_b, fixed_aug_shot=True):\n",
    "        self.base_transform_a = base_transform_a\n",
    "        self.base_transform_b = base_transform_b\n",
    "        self.fixed = fixed_aug_shot\n",
    "\n",
    "    def __call__(self, x):\n",
    "        frame_num = len(x)\n",
    "        if self.fixed:\n",
    "            seed = np.random.randint(2147483647)\n",
    "            q, k = [], []\n",
    "            for i in range(frame_num):\n",
    "                random.seed(seed)\n",
    "                q.append(self.base_transform_a(x[i]))\n",
    "            seed = np.random.randint(2147483647)\n",
    "            for i in range(frame_num):\n",
    "                random.seed(seed)\n",
    "                k.append(self.base_transform_b(x[i]))\n",
    "        else:\n",
    "            q = [self.base_transform_a(x[i]) for i in range(frame_num)]\n",
    "            k = [self.base_transform_b(x[i]) for i in range(frame_num)]\n",
    "        q = torch.cat(q, axis = 0)\n",
    "        k = torch.cat(k, axis = 0)\n",
    "        return [q, k]\n",
    "\n",
    "class MovieNet_Shot_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_path, shot_info_path, transform,\n",
    "        shot_len = 16, frame_per_shot = 3, _Type='train'):\n",
    "        self.img_path = img_path\n",
    "        with open(shot_info_path, 'rb') as f:\n",
    "            self.shot_info = json.load(f)\n",
    "        self.img_path = img_path\n",
    "        self.shot_len = shot_len\n",
    "        self.frame_per_shot = frame_per_shot\n",
    "        self.transform = transform\n",
    "        self._Type = _Type.lower()\n",
    "        assert self._Type in ['train','val','test']\n",
    "        self.idx_imdb_map = {}\n",
    "        data_length = 0\n",
    "        for imdb, shot_num in self.shot_info[_Type].items():\n",
    "            for i in range(shot_num // shot_len):\n",
    "                self.idx_imdb_map[data_length] = (imdb, i)\n",
    "                data_length += 1\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.idx_imdb_map.keys())\n",
    "    \n",
    "    def _transform(self, img_list):\n",
    "        q, k = [], []\n",
    "        for item in img_list:\n",
    "            out = self.transform(item)\n",
    "            q.append(out[0])\n",
    "            k.append(out[1])\n",
    "        out_q = torch.stack(q, axis=0)\n",
    "        out_k = torch.stack(k, axis=0)\n",
    "        return [out_q, out_k]\n",
    "    \n",
    "    def _process_puzzle(self, idx):\n",
    "        imdb, puzzle_id = self.idx_imdb_map[idx]\n",
    "        img_path =  f'{self.img_path}/{imdb}/{str(puzzle_id).zfill(4)}.jpg'\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = np.vsplit(img, self.shot_len)\n",
    "        img = [np.hsplit(i, self.frame_per_shot) for i in img]\n",
    "        data = self._transform(img)\n",
    "        return data\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self._process_puzzle(idx)\n",
    "\n",
    "def get_train_loader(cfg):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225]) \n",
    "    augmentation_base = [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        #normalize\n",
    "    ]\n",
    "\n",
    "    train_transform = TwoWayTransform(\n",
    "        transforms.Compose(augmentation_base), \n",
    "        transforms.Compose(augmentation_base),\n",
    "        fixed_aug_shot=cfg['data']['fixed_aug_shot'])\n",
    "\n",
    "    img_path = cfg['data']['data_path'] \n",
    "    shot_info_path = cfg['data']['shot_info'] \n",
    "    train_dataset = MovieNet_Shot_Dataset(img_path, shot_info_path, train_transform)\n",
    "    train_sampler = None\n",
    "    if False:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, shuffle=True)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "        shuffle=(train_sampler is None),\n",
    "        batch_size=16, num_workers=8, pin_memory=True, drop_last=True) #36\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "625 MB\n"
     ]
    }
   ],
   "source": [
    "cfg = yaml.safe_load(open(\"./config/vllip_pretrain.yaml\", encoding='utf8'))\n",
    "def load_dino(model_config_path, model_checkpoint_path, device):\n",
    "    args = SLConfig.fromfile(model_config_path)\n",
    "    args.device = device\n",
    "    model = build_model(args)\n",
    "    checkpoint = torch.load(model_checkpoint_path, map_location=\"cpu\")\n",
    "    load_res = model.load_state_dict(clean_state_dict(checkpoint[\"model\"]), strict=False)\n",
    "    print(load_res)\n",
    "    _ = model.eval()\n",
    "    return model\n",
    "dino = load_dino(cfg[\"model\"][\"dino_config_path\"], cfg[\"model\"][\"dino_pretrain\"], device=f'cuda:{torch.cuda.current_device()}')\n",
    "sam = sam_model_registry[\"vit_t\"](checkpoint=cfg[\"model\"][\"sam_pretrain\"]).cuda()\n",
    "clip_vit = CLIPViTFM(batch_size=16*16, model_name='ViT-B/32').cuda()\n",
    "#clip_res = clip_backbone(batch_size=16*16, model_name='RN50').cuda()\n",
    "train_loader = get_train_loader(cfg)  \n",
    "print(int(torch.cuda.max_memory_allocated(device='cuda')/1024**2),\"MB\") #DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VLLIP_vit_encoder(nn.Module):\n",
    "    def __init__(self,dino, sam, clip):\n",
    "        super(VLLIP_vit_encoder, self).__init__()\n",
    "        self.dino = dino\n",
    "        self.sam = sam\n",
    "        self.clip = clip\n",
    "         \n",
    "    def forward(self, images, type):\n",
    "        #shots = images.clone()\n",
    "        images = images.reshape(images.size()[0]*3, 3, 224, 224)\n",
    "        assert type =='train' or type=='test'\n",
    "        if type=='train':\n",
    "            mask_list = torch.ones(images.size()[0], 1, 224, 224)\n",
    "            #mask_list = mask_list.reshape(int(images.size()[0]/3),3,224,224)\n",
    "\n",
    "        elif type=='test':    \n",
    "            # Ground DINO\n",
    "            boxes_filt, _, _ = self.get_grounding_output(\n",
    "                self.dino, images, \"human\", 0.45, 0.25)\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # SAM\n",
    "            images = (images * 255).clamp(0, 255).to(torch.uint8) # bs, 3, 224, 224\n",
    "            resize_transform = ResizeLongestSide(self.sam.image_encoder.img_size)\n",
    "        \n",
    "            \"\"\"\n",
    "            for i in range(10,14): # !!!DEBUG!!! \n",
    "                plt.imshow(images[i].permute(1, 2, 0))\n",
    "                plt.show()\n",
    "            \"\"\"\n",
    "        \n",
    "            batched_input = []\n",
    "            for i in range(images.size()[0]):                \n",
    "                prepared_image = self.prepare_image(images[i], resize_transform)   \n",
    "                transformed_boxes = self.transform_boxes(boxes_filt[i],images[i],resize_transform)\n",
    "                batched_input.append({\n",
    "                    'image': prepared_image,\n",
    "                    'boxes': transformed_boxes,\n",
    "                    'original_size': images[i].shape[1:] \n",
    "                })\n",
    "            with torch.no_grad():    \n",
    "                outputs = self.sam(batched_input, multimask_output=False)\n",
    "            \n",
    "            mask_list = []\n",
    "            for i, output in enumerate(outputs):\n",
    "                if output[\"masks\"] != None:\n",
    "                    output[\"masks\"] = output[\"masks\"].cpu()\n",
    "                    output[\"masks\"] = output[\"masks\"].any(dim=0)\n",
    "                    output[\"masks\"] = (~output[\"masks\"]).int()\n",
    "                    mask_list.append(output[\"masks\"])\n",
    "                else:\n",
    "                    mask_list.append(torch.ones([1, 224, 224]))\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            mask_list = torch.stack(mask_list)\n",
    "        \n",
    "        \"\"\"\n",
    "        main_color = np.array([255, 255, 255, 255]) #배경색 - 흰색\n",
    "        subtract_color = np.array([255, 255, 255, 0]) #마스크(사람) - 검정색\n",
    "        for i in range(10,14): # !!!DEBUG!!! \n",
    "            H, W =images[i].size()[1], images[i].size()[2] #224, 224\n",
    "            mask_data = mask_list[i].numpy()\n",
    "            bg_image = np.full((H, W, 4), main_color, dtype=np.float64)\n",
    "            mask_image = mask_data.reshape(H, W, 1) * subtract_color.reshape(1, 1, -1)\n",
    "            final_image = bg_image.copy()\n",
    "            final_image -= mask_image\n",
    "            plt.imshow(final_image)\n",
    "            plt.show()\n",
    "        \"\"\"\n",
    "\n",
    "        #CLIP ViT\n",
    "        visual_features = self.clip(images.cuda(), mask_list.cuda(), masking_type='token_masking', masking_block=9)\n",
    "        visual_features = visual_features.cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "        return visual_features\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_grounding_output(self, model, image, caption, box_threshold, text_threshold, with_logits=True):\n",
    "        caption = caption.lower()\n",
    "        caption = caption.strip()\n",
    "        if not caption.endswith(\".\"):\n",
    "            caption = caption + \".\"\n",
    "        captions = [caption]*image.size()[0]\n",
    "        images = image.cuda()\n",
    "        model = model.cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images, captions=captions)\n",
    "\n",
    "        prediction_logits = outputs[\"pred_logits\"].cpu().sigmoid()  # (bs, nq, 256)\n",
    "        prediction_boxes = outputs[\"pred_boxes\"].cpu()  # (bs, nq, 4)\n",
    "        \n",
    "        logits_res = [] #length: bs\n",
    "        boxs_res = [] #length: bs\n",
    "        phrases_list = [] #length: bs\n",
    "        tokenizer = model.tokenizer\n",
    "        for ub_logits, ub_boxes, ub_captions in zip(prediction_logits, prediction_boxes, captions):\n",
    "            mask = ub_logits.max(dim=1)[0] > box_threshold\n",
    "            logits = ub_logits[mask]  # logits.shape = (n, 256)\n",
    "            boxes = ub_boxes[mask]  # boxes.shape = (n, 4)\n",
    "            logits_res.append(logits.max(dim=1)[0])\n",
    "            boxs_res.append(boxes)\n",
    "\n",
    "            tokenized = tokenizer(ub_captions)\n",
    "            phrases = [\n",
    "                get_phrases_from_posmap(logit > text_threshold, tokenized, tokenizer).replace('.', '')\n",
    "                for logit\n",
    "                in logits\n",
    "            ]\n",
    "            phrases_list.append(phrases)\n",
    "        return boxs_res, phrases_list, logits_res,\n",
    "    @torch.no_grad()\n",
    "    def transform_boxes(self, boxes_filt, image, transform):\n",
    "        H, W = image.size()[1], image.size()[2] #224, 224\n",
    "        for i in range(boxes_filt.size(0)): #XYWH -> X1Y1X2Y2 형식 변경\n",
    "            boxes_filt[i] = boxes_filt[i] * torch.Tensor([W, H, W, H])\n",
    "            boxes_filt[i][:2] -= boxes_filt[i][2:] / 2\n",
    "            boxes_filt[i][2:] += boxes_filt[i][:2]\n",
    "        boxes_filt = boxes_filt.cpu()\n",
    "        transformed_boxes = transform.apply_boxes_torch(boxes_filt, image.shape[1:]).cuda()\n",
    "        return transformed_boxes\n",
    "    @torch.no_grad()\n",
    "    def prepare_image(self, image, transform):\n",
    "        image = transform.apply_image(image) #3, 224, 224 -> 1024, 1024, 3\n",
    "        image = torch.as_tensor(image) #to cuda\n",
    "        image = image.cuda()\n",
    "        return image.permute(2, 0, 1).contiguous() #1024, 1024, 3 -> 3, 1024, 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VLLIP_res_encoder(nn.Module):\n",
    "    def __init__(self,dino, sam, clip):\n",
    "        super(VLLIP_res_encoder, self).__init__()\n",
    "        self.dino = dino\n",
    "        self.sam = sam\n",
    "        self.clip = clip\n",
    "         \n",
    "    def forward(self, images, type):\n",
    "        shots = images.clone()\n",
    "        images = images.reshape(images.size()[0]*3, 3, 224, 224)\n",
    "        assert type =='train' or type=='test'\n",
    "        if type=='train':\n",
    "            mask_list = torch.ones(images.size()[0], 1, 224, 224)\n",
    "            mask_list = mask_list.reshape(int(images.size()[0]/3),3,224,224)\n",
    "\n",
    "        elif type=='test':    \n",
    "            # Ground DINO\n",
    "            boxes_filt, _, _ = self.get_grounding_output(\n",
    "                self.dino, images, \"human\", 0.45, 0.25)\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # SAM\n",
    "            images = (images * 255).clamp(0, 255).to(torch.uint8) # bs, 3, 224, 224\n",
    "            resize_transform = ResizeLongestSide(self.sam.image_encoder.img_size)\n",
    "        \n",
    "            \"\"\"\n",
    "            for i in range(10,14): # !!!DEBUG!!! \n",
    "                plt.imshow(images[i].permute(1, 2, 0))\n",
    "                plt.show()\n",
    "            \"\"\"\n",
    "        \n",
    "            batched_input = []\n",
    "            for i in range(images.size()[0]):                \n",
    "                prepared_image = self.prepare_image(images[i], resize_transform)   \n",
    "                transformed_boxes = self.transform_boxes(boxes_filt[i],images[i],resize_transform)\n",
    "                batched_input.append({\n",
    "                    'image': prepared_image,\n",
    "                    'boxes': transformed_boxes,\n",
    "                    'original_size': images[i].shape[1:] \n",
    "                })\n",
    "            with torch.no_grad():    \n",
    "                outputs = self.sam(batched_input, multimask_output=False)\n",
    "            \n",
    "            mask_list = []\n",
    "            for i, output in enumerate(outputs):\n",
    "                if output[\"masks\"] != None:\n",
    "                    output[\"masks\"] = output[\"masks\"].cpu()\n",
    "                    output[\"masks\"] = output[\"masks\"].any(dim=0)\n",
    "                    output[\"masks\"] = (~output[\"masks\"]).int()\n",
    "                    mask_list.append(output[\"masks\"])\n",
    "                else:\n",
    "                    mask_list.append(torch.ones([1, 224, 224]))\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            mask_list = torch.stack(mask_list)\n",
    "\n",
    "        #CLIP ResNet\n",
    "        visual_features = self.clip.feature_map_masking(shots.cuda(), mask_list.cuda())\n",
    "        visual_features.cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "        return visual_features\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_grounding_output(self, model, image, caption, box_threshold, text_threshold, with_logits=True):\n",
    "        caption = caption.lower()\n",
    "        caption = caption.strip()\n",
    "        if not caption.endswith(\".\"):\n",
    "            caption = caption + \".\"\n",
    "        captions = [caption]*image.size()[0]\n",
    "        images = image.cuda()\n",
    "        model = model.cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images, captions=captions)\n",
    "\n",
    "        prediction_logits = outputs[\"pred_logits\"].cpu().sigmoid()  # (bs, nq, 256)\n",
    "        prediction_boxes = outputs[\"pred_boxes\"].cpu()  # (bs, nq, 4)\n",
    "        \n",
    "        logits_res = [] #length: bs\n",
    "        boxs_res = [] #length: bs\n",
    "        phrases_list = [] #length: bs\n",
    "        tokenizer = model.tokenizer\n",
    "        for ub_logits, ub_boxes, ub_captions in zip(prediction_logits, prediction_boxes, captions):\n",
    "            mask = ub_logits.max(dim=1)[0] > box_threshold\n",
    "            logits = ub_logits[mask]  # logits.shape = (n, 256)\n",
    "            boxes = ub_boxes[mask]  # boxes.shape = (n, 4)\n",
    "            logits_res.append(logits.max(dim=1)[0])\n",
    "            boxs_res.append(boxes)\n",
    "\n",
    "            tokenized = tokenizer(ub_captions)\n",
    "            phrases = [\n",
    "                get_phrases_from_posmap(logit > text_threshold, tokenized, tokenizer).replace('.', '')\n",
    "                for logit\n",
    "                in logits\n",
    "            ]\n",
    "            phrases_list.append(phrases)\n",
    "        return boxs_res, phrases_list, logits_res,\n",
    "    @torch.no_grad()\n",
    "    def transform_boxes(self, boxes_filt, image, transform):\n",
    "        H, W = image.size()[1], image.size()[2] #224, 224\n",
    "        for i in range(boxes_filt.size(0)): #XYWH -> X1Y1X2Y2 형식 변경\n",
    "            boxes_filt[i] = boxes_filt[i] * torch.Tensor([W, H, W, H])\n",
    "            boxes_filt[i][:2] -= boxes_filt[i][2:] / 2\n",
    "            boxes_filt[i][2:] += boxes_filt[i][:2]\n",
    "        boxes_filt = boxes_filt.cpu()\n",
    "        transformed_boxes = transform.apply_boxes_torch(boxes_filt, image.shape[1:]).cuda()\n",
    "        return transformed_boxes\n",
    "    @torch.no_grad()\n",
    "    def prepare_image(self, image, transform):\n",
    "        image = transform.apply_image(image) #3, 224, 224 -> 1024, 1024, 3\n",
    "        image = torch.as_tensor(image) #to cuda\n",
    "        image = image.cuda()\n",
    "        return image.permute(2, 0, 1).contiguous() #1024, 1024, 3 -> 3, 1024, 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VLLIP(nn.Module):\n",
    "    def __init__(self, dino, sam, clip, type):\n",
    "        super(VLLIP,self).__init__()\n",
    "        self.dino = dino\n",
    "        self.sam = sam\n",
    "        self.clip = clip\n",
    "        self.type = type\n",
    "\n",
    "        self.q_encoder = VLLIP_vit_encoder(self.dino, self.sam, self.clip)\n",
    "        self.k_encoder = VLLIP_vit_encoder(self.dino, self.sam, self.clip)\n",
    "        #self.q_encoder = VLLIP_res_encoder(self.dino, self.sam, self.clip)\n",
    "        #self.k_encoder = VLLIP_res_encoder(self.dino, self.sam, self.clip)\n",
    "        \n",
    "        self.cluster_num = 24\n",
    "        self.cluster_obj = Cluster_GPU(self.cluster_num)\n",
    "        self.multi_positive = True\n",
    "        self.soft_gamma = 0.5\n",
    "        self.K = 16384 #32768 #16384 #65536\n",
    "        self.m = 0.999\n",
    "        self.T = 0.07\n",
    "        self.dim = 512\n",
    "        \n",
    "        for param_q, param_k in zip(self.q_encoder.clip.parameters(), self.k_encoder.clip.parameters()): #Q인코더 K인코더로 파라미터 복사 후 freeze\n",
    "            param_k.data.copy_(param_q.data)  \n",
    "            param_k.requires_grad = False \n",
    "        \n",
    "        # create the queue\n",
    "        self.register_buffer(\"queue\", torch.randn(self.dim, self.K)) # 512 x 16384 행렬\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "        # queue 길이 = 16384, queue 차원 = 512\n",
    "\n",
    "    def forward(self, img_q, img_k): #SCRL과 동일함\n",
    "        embeddings = self.q_encoder(img_q, self.type) # bs, 512\n",
    "        embeddings = nn.functional.normalize(embeddings, dim=1) # bs, 512\n",
    "        \n",
    "        # get q and k index\n",
    "        index_q, index_k = self.get_q_and_k_index_cluster(embeddings) # q 임베딩 입력 -> 0~bs, k-index\n",
    "        \n",
    "        # features of q\n",
    "        q = embeddings[index_q] # embeddings\n",
    "        q = q.cuda()\n",
    "\n",
    "        # compute key features\n",
    "        with torch.no_grad():  \n",
    "            # update the key encoder\n",
    "            self._momentum_update_key_encoder() #k encoder param update\n",
    "\n",
    "            # shuffle for making use of BN\n",
    "            # img_k, idx_unshuffle = self._batch_shuffle_ddp(img_k)\n",
    "\n",
    "            k = self.k_encoder(img_k, self.type) # bs, 512\n",
    "            k = nn.functional.normalize(k, dim=1)\n",
    "            k = k.cuda()\n",
    "            \n",
    "            # undo shuffle\n",
    "            # k = self._batch_unshuffle_ddp(k, idx_unshuffle)\n",
    "\n",
    "        k_ori = k\n",
    "        k = k[index_k] #k indexes 선택\n",
    "\n",
    "        # compute logits\n",
    "        # positive logits: Nx1\n",
    "        if self.multi_positive: # True\n",
    "            # SCRL Soft-SC \n",
    "            k = (k + k_ori) * self.soft_gamma # original_k + k\n",
    "\n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1) #내적 - attntion 같은 느낌\n",
    "\n",
    "        \n",
    "        # negative logits: NxK\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()]) #외적\n",
    "\n",
    "        # logits: Nx(1+K)\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1) #연접\n",
    "\n",
    "        # apply temperature\n",
    "        logits /= self.T #scalinng\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda() #전부 0 나옴\n",
    "\n",
    "        # dequeue and enqueue\n",
    "        self._dequeue_and_enqueue(k)\n",
    "        \n",
    "        return logits, labels\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_q_and_k_index_cluster(self, embeddings, return_group=False) -> tuple:\n",
    "\n",
    "        B = embeddings.size(0) #bs\n",
    "        target_index = list(range(0, B)) #0~bs\n",
    "        q_index = target_index #0~bs\n",
    "\n",
    "        choice_cluster, choice_points = self.cluster_obj(embeddings) #clustering\n",
    "        k_index = []\n",
    "        for c in choice_cluster:\n",
    "            k_index.append(int(choice_points[c])) #cluster centers\n",
    "        if return_group: #False\n",
    "            return (q_index, k_index, choice_cluster, choice_points)\n",
    "        else:\n",
    "            return (q_index, k_index)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(self.q_encoder.clip.parameters(), self.k_encoder.clip.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "    \n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        # gather keys before updating queue\n",
    "        # keys = concat_all_gather(keys)\n",
    "\n",
    "        batch_size = keys.shape[0]\n",
    "        \n",
    "        ptr = int(self.queue_ptr)\n",
    "        \n",
    "        assert self.K % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.T\n",
    "        ptr = (ptr + batch_size) % self.K  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    \"\"\"\n",
    "    @torch.no_grad()\n",
    "    def concat_all_gather(tensor):\n",
    "        \n",
    "        #Performs all_gather operation on the provided tensors.\n",
    "        #*** Warning ***: torch.distributed.all_gather has no gradient.\n",
    "        \n",
    "        tensors_gather = [torch.ones_like(tensor)\n",
    "        for _ in range(torch.distributed.get_world_size())]\n",
    "        torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
    "\n",
    "        output = torch.cat(tensors_gather, dim=0)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_ddp(self, x):\n",
    "        \n",
    "        #Batch shuffle, for making use of BatchNorm.\n",
    "        #*** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # random shuffle index\n",
    "        idx_shuffle = torch.randperm(batch_size_all).cuda()\n",
    "\n",
    "        # broadcast to all gpus\n",
    "        torch.distributed.broadcast(idx_shuffle, src=0)\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "        # shuffled index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this], idx_unshuffle\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_ddp(self, x, idx_unshuffle):\n",
    "        \n",
    "        #Undo batch shuffle.\n",
    "        #*** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # restored index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this]\n",
    "    \"\"\"\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_q_and_k_index_cluster(self, embeddings, return_group=False) -> tuple:\n",
    "\n",
    "        B = embeddings.size(0) # bs\n",
    "        target_index = list(range(0, B)) # 0...bs-1\n",
    "        q_index = target_index # 0...bs-1\n",
    "\n",
    "        choice_cluster, choice_points = self.cluster_obj(embeddings)\n",
    "        k_index = []\n",
    "        for c in choice_cluster:\n",
    "            k_index.append(int(choice_points[c]))\n",
    "        if return_group:\n",
    "            return (q_index, k_index, choice_cluster, choice_points)\n",
    "        else:\n",
    "            return (q_index, k_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnstar1125\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/vllip/wandb/run-20240408_121904-9ovqz5wj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nstar1125/VLLIP/runs/9ovqz5wj' target=\"_blank\">frosty-armadillo-95</a></strong> to <a href='https://wandb.ai/nstar1125/VLLIP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nstar1125/VLLIP' target=\"_blank\">https://wandb.ai/nstar1125/VLLIP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nstar1125/VLLIP/runs/9ovqz5wj' target=\"_blank\">https://wandb.ai/nstar1125/VLLIP/runs/9ovqz5wj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1316 MB\n",
      "[0 epoch](0/3742 iteration) lr: 0.0000, loss: 0.9928, acc1: 100.0000, acc5: 100.0000, elapsed_time: 1.9559s\n",
      "[0 epoch](1/3742 iteration) lr: 0.0000, loss: 3.0997, acc1: 87.1094, acc5: 93.3594, elapsed_time: 1.6778s\n",
      "[0 epoch](2/3742 iteration) lr: 0.0000, loss: 3.7281, acc1: 77.3438, acc5: 89.4531, elapsed_time: 1.6112s\n",
      "[0 epoch](3/3742 iteration) lr: 0.0000, loss: 3.9636, acc1: 82.4219, acc5: 94.1406, elapsed_time: 1.8219s\n",
      "[0 epoch](4/3742 iteration) lr: 0.0000, loss: 4.1853, acc1: 72.2656, acc5: 88.2812, elapsed_time: 1.5686s\n",
      "[0 epoch](5/3742 iteration) lr: 0.0000, loss: 4.5402, acc1: 63.2812, acc5: 82.0312, elapsed_time: 1.3769s\n",
      "[0 epoch](6/3742 iteration) lr: 0.0000, loss: 4.5786, acc1: 72.2656, acc5: 85.9375, elapsed_time: 1.3791s\n",
      "[0 epoch](7/3742 iteration) lr: 0.0000, loss: 4.6694, acc1: 75.7812, acc5: 88.2812, elapsed_time: 1.3833s\n",
      "[0 epoch](8/3742 iteration) lr: 0.0000, loss: 4.6106, acc1: 82.8125, acc5: 91.7969, elapsed_time: 1.3807s\n",
      "[0 epoch](9/3742 iteration) lr: 0.0000, loss: 4.9530, acc1: 73.4375, acc5: 90.2344, elapsed_time: 1.3881s\n",
      "[0 epoch](10/3742 iteration) lr: 0.0000, loss: 5.0720, acc1: 62.8906, acc5: 79.2969, elapsed_time: 1.3860s\n",
      "[0 epoch](11/3742 iteration) lr: 0.0000, loss: 5.3064, acc1: 62.8906, acc5: 74.6094, elapsed_time: 1.3789s\n",
      "[0 epoch](12/3742 iteration) lr: 0.0000, loss: 5.2812, acc1: 64.8438, acc5: 78.9062, elapsed_time: 1.3755s\n",
      "[0 epoch](13/3742 iteration) lr: 0.0000, loss: 5.3168, acc1: 57.8125, acc5: 79.2969, elapsed_time: 1.3695s\n",
      "[0 epoch](14/3742 iteration) lr: 0.0000, loss: 5.3309, acc1: 67.5781, acc5: 80.0781, elapsed_time: 1.3820s\n",
      "[0 epoch](15/3742 iteration) lr: 0.0000, loss: 5.4757, acc1: 60.9375, acc5: 74.6094, elapsed_time: 1.3925s\n",
      "[0 epoch](16/3742 iteration) lr: 0.0000, loss: 5.4534, acc1: 63.6719, acc5: 79.6875, elapsed_time: 1.3841s\n",
      "[0 epoch](17/3742 iteration) lr: 0.0000, loss: 5.5975, acc1: 60.5469, acc5: 76.5625, elapsed_time: 1.3828s\n",
      "[0 epoch](18/3742 iteration) lr: 0.0000, loss: 5.6080, acc1: 62.5000, acc5: 83.2031, elapsed_time: 1.3886s\n",
      "[0 epoch](19/3742 iteration) lr: 0.0000, loss: 5.6244, acc1: 59.3750, acc5: 77.7344, elapsed_time: 1.3924s\n",
      "[0 epoch](20/3742 iteration) lr: 0.0000, loss: 5.7666, acc1: 57.8125, acc5: 72.6562, elapsed_time: 1.3998s\n",
      "[0 epoch](21/3742 iteration) lr: 0.0000, loss: 5.9514, acc1: 45.3125, acc5: 68.3594, elapsed_time: 1.3825s\n",
      "[0 epoch](22/3742 iteration) lr: 0.0000, loss: 5.8289, acc1: 55.8594, acc5: 71.4844, elapsed_time: 1.3824s\n",
      "[0 epoch](23/3742 iteration) lr: 0.0000, loss: 5.8750, acc1: 59.3750, acc5: 75.3906, elapsed_time: 1.3835s\n",
      "[0 epoch](24/3742 iteration) lr: 0.0000, loss: 5.9639, acc1: 55.8594, acc5: 70.3125, elapsed_time: 1.3891s\n",
      "[0 epoch](25/3742 iteration) lr: 0.0000, loss: 5.9425, acc1: 52.7344, acc5: 67.9688, elapsed_time: 1.3889s\n",
      "[0 epoch](26/3742 iteration) lr: 0.0000, loss: 5.8606, acc1: 62.5000, acc5: 82.8125, elapsed_time: 1.3888s\n",
      "[0 epoch](27/3742 iteration) lr: 0.0000, loss: 6.1868, acc1: 50.0000, acc5: 68.3594, elapsed_time: 1.4079s\n",
      "[0 epoch](28/3742 iteration) lr: 0.0000, loss: 6.0165, acc1: 47.6562, acc5: 66.4062, elapsed_time: 1.3876s\n",
      "[0 epoch](29/3742 iteration) lr: 0.0000, loss: 6.1849, acc1: 45.7031, acc5: 62.5000, elapsed_time: 1.3928s\n",
      "[0 epoch](30/3742 iteration) lr: 0.0000, loss: 6.2130, acc1: 49.6094, acc5: 64.8438, elapsed_time: 1.3848s\n",
      "[0 epoch](31/3742 iteration) lr: 0.0000, loss: 6.0171, acc1: 63.6719, acc5: 76.9531, elapsed_time: 1.3890s\n",
      "[0 epoch](32/3742 iteration) lr: 0.0000, loss: 6.1448, acc1: 50.7812, acc5: 69.9219, elapsed_time: 1.3989s\n",
      "[0 epoch](33/3742 iteration) lr: 0.0000, loss: 6.2275, acc1: 55.4688, acc5: 70.3125, elapsed_time: 1.3874s\n",
      "[0 epoch](34/3742 iteration) lr: 0.0000, loss: 6.1755, acc1: 51.1719, acc5: 66.0156, elapsed_time: 1.3953s\n",
      "[0 epoch](35/3742 iteration) lr: 0.0000, loss: 6.2705, acc1: 47.2656, acc5: 66.0156, elapsed_time: 1.3903s\n",
      "[0 epoch](36/3742 iteration) lr: 0.0000, loss: 5.9407, acc1: 62.8906, acc5: 79.6875, elapsed_time: 1.4085s\n",
      "[0 epoch](37/3742 iteration) lr: 0.0000, loss: 6.2593, acc1: 48.0469, acc5: 63.6719, elapsed_time: 1.3940s\n",
      "[0 epoch](38/3742 iteration) lr: 0.0000, loss: 6.3037, acc1: 46.4844, acc5: 64.4531, elapsed_time: 1.3876s\n",
      "[0 epoch](39/3742 iteration) lr: 0.0000, loss: 6.3246, acc1: 47.6562, acc5: 69.9219, elapsed_time: 1.3939s\n",
      "[0 epoch](40/3742 iteration) lr: 0.0000, loss: 6.4288, acc1: 50.3906, acc5: 72.2656, elapsed_time: 1.3863s\n",
      "[0 epoch](41/3742 iteration) lr: 0.0000, loss: 6.5266, acc1: 36.7188, acc5: 49.2188, elapsed_time: 1.4011s\n",
      "[0 epoch](42/3742 iteration) lr: 0.0000, loss: 6.5133, acc1: 47.6562, acc5: 62.5000, elapsed_time: 1.4005s\n",
      "[0 epoch](43/3742 iteration) lr: 0.0000, loss: 6.4703, acc1: 52.3438, acc5: 67.9688, elapsed_time: 1.3960s\n",
      "[0 epoch](44/3742 iteration) lr: 0.0000, loss: 6.3735, acc1: 48.8281, acc5: 68.3594, elapsed_time: 1.3965s\n",
      "[0 epoch](45/3742 iteration) lr: 0.0000, loss: 6.7251, acc1: 33.5938, acc5: 50.7812, elapsed_time: 1.4078s\n",
      "[0 epoch](46/3742 iteration) lr: 0.0000, loss: 6.2873, acc1: 58.2031, acc5: 76.5625, elapsed_time: 1.3980s\n",
      "[0 epoch](47/3742 iteration) lr: 0.0000, loss: 6.6286, acc1: 38.2812, acc5: 60.1562, elapsed_time: 1.3861s\n",
      "[0 epoch](48/3742 iteration) lr: 0.0000, loss: 6.4823, acc1: 55.8594, acc5: 76.5625, elapsed_time: 1.3865s\n",
      "[0 epoch](49/3742 iteration) lr: 0.0000, loss: 6.4608, acc1: 56.2500, acc5: 75.3906, elapsed_time: 1.4086s\n",
      "[0 epoch](50/3742 iteration) lr: 0.0000, loss: 6.8535, acc1: 38.6719, acc5: 56.6406, elapsed_time: 1.4020s\n",
      "[0 epoch](51/3742 iteration) lr: 0.0000, loss: 6.4831, acc1: 51.9531, acc5: 68.7500, elapsed_time: 1.4063s\n",
      "[0 epoch](52/3742 iteration) lr: 0.0000, loss: 6.4763, acc1: 60.5469, acc5: 76.5625, elapsed_time: 1.3982s\n",
      "[0 epoch](53/3742 iteration) lr: 0.0000, loss: 6.7421, acc1: 42.5781, acc5: 60.1562, elapsed_time: 1.3926s\n",
      "[0 epoch](54/3742 iteration) lr: 0.0000, loss: 6.7479, acc1: 41.7969, acc5: 58.5938, elapsed_time: 1.3937s\n",
      "[0 epoch](55/3742 iteration) lr: 0.0000, loss: 6.7113, acc1: 44.1406, acc5: 62.8906, elapsed_time: 1.3978s\n",
      "[0 epoch](56/3742 iteration) lr: 0.0000, loss: 6.5798, acc1: 53.9062, acc5: 69.5312, elapsed_time: 1.4024s\n",
      "[0 epoch](57/3742 iteration) lr: 0.0000, loss: 6.6993, acc1: 54.2969, acc5: 71.0938, elapsed_time: 1.3911s\n",
      "[0 epoch](58/3742 iteration) lr: 0.0000, loss: 6.5428, acc1: 54.6875, acc5: 74.2188, elapsed_time: 1.3991s\n",
      "[0 epoch](59/3742 iteration) lr: 0.0000, loss: 6.7433, acc1: 44.1406, acc5: 64.0625, elapsed_time: 1.4070s\n",
      "[0 epoch](60/3742 iteration) lr: 0.0000, loss: 6.9107, acc1: 42.5781, acc5: 56.6406, elapsed_time: 1.4002s\n",
      "[0 epoch](61/3742 iteration) lr: 0.0000, loss: 6.8718, acc1: 38.2812, acc5: 57.0312, elapsed_time: 1.4054s\n",
      "[0 epoch](62/3742 iteration) lr: 0.0000, loss: 6.5793, acc1: 54.2969, acc5: 71.8750, elapsed_time: 1.3950s\n",
      "[0 epoch](63/3742 iteration) lr: 0.0000, loss: 6.7821, acc1: 47.2656, acc5: 60.9375, elapsed_time: 1.4022s\n",
      "[0 epoch](64/3742 iteration) lr: 0.0000, loss: 6.7826, acc1: 45.7031, acc5: 66.7969, elapsed_time: 1.3915s\n",
      "[0 epoch](65/3742 iteration) lr: 0.0000, loss: 6.8273, acc1: 43.7500, acc5: 62.8906, elapsed_time: 1.3838s\n",
      "[0 epoch](66/3742 iteration) lr: 0.0000, loss: 6.7576, acc1: 54.6875, acc5: 69.1406, elapsed_time: 1.3966s\n",
      "[0 epoch](67/3742 iteration) lr: 0.0000, loss: 6.6556, acc1: 53.1250, acc5: 68.3594, elapsed_time: 1.3987s\n",
      "[0 epoch](68/3742 iteration) lr: 0.0000, loss: 6.7667, acc1: 52.3438, acc5: 75.7812, elapsed_time: 1.4062s\n",
      "[0 epoch](69/3742 iteration) lr: 0.0000, loss: 6.7778, acc1: 52.7344, acc5: 72.6562, elapsed_time: 1.3928s\n",
      "[0 epoch](70/3742 iteration) lr: 0.0000, loss: 6.6935, acc1: 55.0781, acc5: 74.6094, elapsed_time: 1.3924s\n",
      "[0 epoch](71/3742 iteration) lr: 0.0000, loss: 6.8151, acc1: 48.0469, acc5: 69.1406, elapsed_time: 1.3944s\n",
      "[0 epoch](72/3742 iteration) lr: 0.0000, loss: 6.8685, acc1: 42.9688, acc5: 68.7500, elapsed_time: 1.3889s\n",
      "[0 epoch](73/3742 iteration) lr: 0.0000, loss: 6.8538, acc1: 41.0156, acc5: 58.9844, elapsed_time: 1.4100s\n",
      "[0 epoch](74/3742 iteration) lr: 0.0000, loss: 6.6698, acc1: 51.5625, acc5: 73.0469, elapsed_time: 1.4259s\n",
      "[0 epoch](75/3742 iteration) lr: 0.0000, loss: 6.7886, acc1: 53.9062, acc5: 68.3594, elapsed_time: 1.3805s\n",
      "[0 epoch](76/3742 iteration) lr: 0.0000, loss: 6.8534, acc1: 43.3594, acc5: 60.1562, elapsed_time: 1.4069s\n",
      "[0 epoch](77/3742 iteration) lr: 0.0000, loss: 6.8920, acc1: 35.5469, acc5: 53.5156, elapsed_time: 1.3995s\n",
      "[0 epoch](78/3742 iteration) lr: 0.0000, loss: 6.9435, acc1: 37.8906, acc5: 57.8125, elapsed_time: 1.3860s\n",
      "[0 epoch](79/3742 iteration) lr: 0.0000, loss: 6.9028, acc1: 41.0156, acc5: 59.7656, elapsed_time: 1.4055s\n",
      "[0 epoch](80/3742 iteration) lr: 0.0000, loss: 6.7726, acc1: 48.4375, acc5: 66.0156, elapsed_time: 1.4011s\n",
      "[0 epoch](81/3742 iteration) lr: 0.0000, loss: 6.8343, acc1: 44.5312, acc5: 67.1875, elapsed_time: 1.3974s\n",
      "[0 epoch](82/3742 iteration) lr: 0.0000, loss: 6.9187, acc1: 41.0156, acc5: 58.9844, elapsed_time: 1.4015s\n",
      "[0 epoch](83/3742 iteration) lr: 0.0000, loss: 6.8634, acc1: 45.7031, acc5: 70.3125, elapsed_time: 1.3918s\n",
      "[0 epoch](84/3742 iteration) lr: 0.0000, loss: 7.0634, acc1: 39.4531, acc5: 52.7344, elapsed_time: 1.4058s\n",
      "[0 epoch](85/3742 iteration) lr: 0.0000, loss: 6.8573, acc1: 42.9688, acc5: 60.5469, elapsed_time: 1.4000s\n",
      "[0 epoch](86/3742 iteration) lr: 0.0000, loss: 6.9134, acc1: 36.7188, acc5: 60.1562, elapsed_time: 1.3891s\n",
      "[0 epoch](87/3742 iteration) lr: 0.0000, loss: 6.4497, acc1: 69.5312, acc5: 82.4219, elapsed_time: 1.3931s\n",
      "[0 epoch](88/3742 iteration) lr: 0.0000, loss: 7.0604, acc1: 39.8438, acc5: 57.4219, elapsed_time: 1.4040s\n",
      "[0 epoch](89/3742 iteration) lr: 0.0000, loss: 6.9765, acc1: 34.7656, acc5: 52.7344, elapsed_time: 1.3879s\n",
      "[0 epoch](90/3742 iteration) lr: 0.0000, loss: 6.8423, acc1: 42.5781, acc5: 61.3281, elapsed_time: 1.3968s\n",
      "[0 epoch](91/3742 iteration) lr: 0.0000, loss: 6.7791, acc1: 47.2656, acc5: 67.9688, elapsed_time: 1.3996s\n",
      "[0 epoch](92/3742 iteration) lr: 0.0000, loss: 6.8700, acc1: 49.2188, acc5: 66.0156, elapsed_time: 1.4132s\n",
      "[0 epoch](93/3742 iteration) lr: 0.0000, loss: 6.5421, acc1: 53.1250, acc5: 67.9688, elapsed_time: 1.3864s\n",
      "[0 epoch](94/3742 iteration) lr: 0.0000, loss: 6.8923, acc1: 46.8750, acc5: 65.2344, elapsed_time: 1.4022s\n",
      "[0 epoch](95/3742 iteration) lr: 0.0000, loss: 6.8425, acc1: 44.9219, acc5: 64.0625, elapsed_time: 1.3955s\n",
      "[0 epoch](96/3742 iteration) lr: 0.0000, loss: 6.8362, acc1: 50.0000, acc5: 68.3594, elapsed_time: 1.3974s\n",
      "[0 epoch](97/3742 iteration) lr: 0.0000, loss: 6.7102, acc1: 50.0000, acc5: 69.5312, elapsed_time: 1.3993s\n",
      "[0 epoch](98/3742 iteration) lr: 0.0000, loss: 6.8088, acc1: 36.7188, acc5: 59.3750, elapsed_time: 1.3943s\n",
      "[0 epoch](99/3742 iteration) lr: 0.0000, loss: 6.8092, acc1: 43.3594, acc5: 65.2344, elapsed_time: 1.3967s\n",
      "[0 epoch](100/3742 iteration) lr: 0.0000, loss: 6.7768, acc1: 52.7344, acc5: 67.9688, elapsed_time: 1.4036s\n",
      "[0 epoch](101/3742 iteration) lr: 0.0000, loss: 6.6006, acc1: 58.9844, acc5: 76.1719, elapsed_time: 1.4059s\n",
      "[0 epoch](102/3742 iteration) lr: 0.0000, loss: 6.8455, acc1: 46.8750, acc5: 67.1875, elapsed_time: 1.3922s\n",
      "[0 epoch](103/3742 iteration) lr: 0.0000, loss: 6.8541, acc1: 46.4844, acc5: 66.0156, elapsed_time: 1.3983s\n",
      "[0 epoch](104/3742 iteration) lr: 0.0000, loss: 7.0188, acc1: 39.4531, acc5: 56.6406, elapsed_time: 1.3955s\n",
      "[0 epoch](105/3742 iteration) lr: 0.0000, loss: 6.6653, acc1: 53.9062, acc5: 71.8750, elapsed_time: 1.3969s\n",
      "[0 epoch](106/3742 iteration) lr: 0.0000, loss: 6.5879, acc1: 60.5469, acc5: 78.1250, elapsed_time: 1.4013s\n",
      "[0 epoch](107/3742 iteration) lr: 0.0000, loss: 6.7642, acc1: 51.1719, acc5: 71.0938, elapsed_time: 1.4007s\n",
      "[0 epoch](108/3742 iteration) lr: 0.0000, loss: 6.7069, acc1: 44.1406, acc5: 62.5000, elapsed_time: 1.3950s\n",
      "[0 epoch](109/3742 iteration) lr: 0.0000, loss: 6.7401, acc1: 53.9062, acc5: 68.7500, elapsed_time: 1.4031s\n",
      "[0 epoch](110/3742 iteration) lr: 0.0000, loss: 6.8030, acc1: 52.7344, acc5: 69.1406, elapsed_time: 1.3869s\n",
      "[0 epoch](111/3742 iteration) lr: 0.0000, loss: 6.7873, acc1: 55.8594, acc5: 71.0938, elapsed_time: 1.3999s\n",
      "[0 epoch](112/3742 iteration) lr: 0.0000, loss: 6.9672, acc1: 45.3125, acc5: 58.5938, elapsed_time: 1.3918s\n",
      "[0 epoch](113/3742 iteration) lr: 0.0000, loss: 6.9504, acc1: 44.5312, acc5: 57.8125, elapsed_time: 1.4124s\n",
      "[0 epoch](114/3742 iteration) lr: 0.0000, loss: 6.7365, acc1: 45.3125, acc5: 59.7656, elapsed_time: 1.3941s\n",
      "[0 epoch](115/3742 iteration) lr: 0.0000, loss: 6.8173, acc1: 44.9219, acc5: 63.6719, elapsed_time: 1.4168s\n",
      "[0 epoch](116/3742 iteration) lr: 0.0000, loss: 6.7380, acc1: 54.6875, acc5: 69.1406, elapsed_time: 1.3937s\n",
      "[0 epoch](117/3742 iteration) lr: 0.0000, loss: 6.7719, acc1: 47.2656, acc5: 64.8438, elapsed_time: 1.3993s\n",
      "[0 epoch](118/3742 iteration) lr: 0.0000, loss: 6.6748, acc1: 50.0000, acc5: 73.0469, elapsed_time: 1.3946s\n",
      "[0 epoch](119/3742 iteration) lr: 0.0000, loss: 6.9684, acc1: 35.5469, acc5: 53.9062, elapsed_time: 1.3982s\n",
      "[0 epoch](120/3742 iteration) lr: 0.0000, loss: 7.0063, acc1: 40.2344, acc5: 64.0625, elapsed_time: 1.3898s\n",
      "[0 epoch](121/3742 iteration) lr: 0.0000, loss: 6.9044, acc1: 37.5000, acc5: 55.8594, elapsed_time: 1.4063s\n",
      "[0 epoch](122/3742 iteration) lr: 0.0000, loss: 6.7431, acc1: 54.2969, acc5: 71.4844, elapsed_time: 1.3916s\n",
      "[0 epoch](123/3742 iteration) lr: 0.0000, loss: 6.6890, acc1: 65.2344, acc5: 82.4219, elapsed_time: 1.3937s\n",
      "[0 epoch](124/3742 iteration) lr: 0.0000, loss: 6.6422, acc1: 59.3750, acc5: 78.5156, elapsed_time: 1.3956s\n",
      "[0 epoch](125/3742 iteration) lr: 0.0000, loss: 6.7224, acc1: 43.7500, acc5: 62.8906, elapsed_time: 1.4100s\n",
      "[0 epoch](126/3742 iteration) lr: 0.0000, loss: 7.0019, acc1: 36.7188, acc5: 55.0781, elapsed_time: 1.3955s\n",
      "[0 epoch](127/3742 iteration) lr: 0.0000, loss: 6.7819, acc1: 49.6094, acc5: 66.0156, elapsed_time: 1.3921s\n",
      "[0 epoch](128/3742 iteration) lr: 0.0000, loss: 6.6795, acc1: 50.3906, acc5: 70.7031, elapsed_time: 1.3992s\n",
      "[0 epoch](129/3742 iteration) lr: 0.0000, loss: 6.8160, acc1: 41.4062, acc5: 60.5469, elapsed_time: 1.3991s\n",
      "[0 epoch](130/3742 iteration) lr: 0.0000, loss: 6.8781, acc1: 47.6562, acc5: 66.7969, elapsed_time: 1.3961s\n",
      "[0 epoch](131/3742 iteration) lr: 0.0000, loss: 6.6914, acc1: 51.5625, acc5: 67.1875, elapsed_time: 1.3983s\n",
      "[0 epoch](132/3742 iteration) lr: 0.0000, loss: 6.6613, acc1: 56.2500, acc5: 72.2656, elapsed_time: 1.4015s\n",
      "[0 epoch](133/3742 iteration) lr: 0.0000, loss: 6.8767, acc1: 41.4062, acc5: 58.2031, elapsed_time: 1.4122s\n",
      "[0 epoch](134/3742 iteration) lr: 0.0000, loss: 6.8474, acc1: 38.6719, acc5: 57.0312, elapsed_time: 1.3850s\n",
      "[0 epoch](135/3742 iteration) lr: 0.0000, loss: 6.9665, acc1: 41.7969, acc5: 59.7656, elapsed_time: 1.4041s\n",
      "[0 epoch](136/3742 iteration) lr: 0.0000, loss: 6.7768, acc1: 50.7812, acc5: 66.4062, elapsed_time: 1.3883s\n",
      "[0 epoch](137/3742 iteration) lr: 0.0000, loss: 6.7104, acc1: 51.1719, acc5: 71.8750, elapsed_time: 1.3986s\n",
      "[0 epoch](138/3742 iteration) lr: 0.0000, loss: 6.5468, acc1: 63.6719, acc5: 77.7344, elapsed_time: 1.4040s\n",
      "[0 epoch](139/3742 iteration) lr: 0.0000, loss: 6.8956, acc1: 42.1875, acc5: 61.3281, elapsed_time: 1.3915s\n",
      "[0 epoch](140/3742 iteration) lr: 0.0000, loss: 6.7956, acc1: 44.9219, acc5: 58.5938, elapsed_time: 1.4092s\n",
      "[0 epoch](141/3742 iteration) lr: 0.0000, loss: 6.6480, acc1: 56.6406, acc5: 80.0781, elapsed_time: 1.4146s\n",
      "[0 epoch](142/3742 iteration) lr: 0.0000, loss: 6.7649, acc1: 46.4844, acc5: 67.5781, elapsed_time: 1.3965s\n",
      "[0 epoch](143/3742 iteration) lr: 0.0000, loss: 6.9613, acc1: 35.9375, acc5: 51.9531, elapsed_time: 1.4030s\n",
      "[0 epoch](144/3742 iteration) lr: 0.0000, loss: 6.8172, acc1: 38.2812, acc5: 59.7656, elapsed_time: 1.4023s\n",
      "[0 epoch](145/3742 iteration) lr: 0.0000, loss: 6.7514, acc1: 55.0781, acc5: 72.2656, elapsed_time: 1.4050s\n",
      "[0 epoch](146/3742 iteration) lr: 0.0000, loss: 6.6887, acc1: 50.0000, acc5: 67.5781, elapsed_time: 1.4048s\n",
      "[0 epoch](147/3742 iteration) lr: 0.0000, loss: 6.8176, acc1: 43.7500, acc5: 63.2812, elapsed_time: 1.4101s\n",
      "[0 epoch](148/3742 iteration) lr: 0.0000, loss: 6.8575, acc1: 41.7969, acc5: 64.8438, elapsed_time: 1.3893s\n",
      "[0 epoch](149/3742 iteration) lr: 0.0000, loss: 6.7413, acc1: 48.0469, acc5: 66.7969, elapsed_time: 1.3923s\n",
      "[0 epoch](150/3742 iteration) lr: 0.0000, loss: 6.7687, acc1: 48.8281, acc5: 66.4062, elapsed_time: 1.3966s\n",
      "[0 epoch](151/3742 iteration) lr: 0.0000, loss: 7.0211, acc1: 33.2031, acc5: 46.8750, elapsed_time: 1.4139s\n",
      "[0 epoch](152/3742 iteration) lr: 0.0000, loss: 6.8476, acc1: 40.2344, acc5: 64.0625, elapsed_time: 1.3909s\n",
      "[0 epoch](153/3742 iteration) lr: 0.0000, loss: 6.7885, acc1: 47.6562, acc5: 65.2344, elapsed_time: 1.3977s\n",
      "[0 epoch](154/3742 iteration) lr: 0.0000, loss: 6.6198, acc1: 50.0000, acc5: 70.7031, elapsed_time: 1.3981s\n",
      "[0 epoch](155/3742 iteration) lr: 0.0000, loss: 6.8225, acc1: 48.4375, acc5: 63.2812, elapsed_time: 1.4048s\n",
      "[0 epoch](156/3742 iteration) lr: 0.0000, loss: 6.9022, acc1: 43.3594, acc5: 64.8438, elapsed_time: 1.3873s\n",
      "[0 epoch](157/3742 iteration) lr: 0.0000, loss: 6.7614, acc1: 44.9219, acc5: 59.7656, elapsed_time: 1.4036s\n",
      "[0 epoch](158/3742 iteration) lr: 0.0000, loss: 6.9526, acc1: 43.3594, acc5: 62.5000, elapsed_time: 1.4061s\n",
      "[0 epoch](159/3742 iteration) lr: 0.0000, loss: 6.7632, acc1: 53.5156, acc5: 75.3906, elapsed_time: 1.3985s\n",
      "[0 epoch](160/3742 iteration) lr: 0.0000, loss: 6.6190, acc1: 60.9375, acc5: 78.5156, elapsed_time: 1.3925s\n",
      "[0 epoch](161/3742 iteration) lr: 0.0000, loss: 6.8438, acc1: 45.3125, acc5: 62.8906, elapsed_time: 1.3927s\n",
      "[0 epoch](162/3742 iteration) lr: 0.0000, loss: 6.9735, acc1: 32.4219, acc5: 51.1719, elapsed_time: 1.3984s\n",
      "[0 epoch](163/3742 iteration) lr: 0.0000, loss: 6.7099, acc1: 55.8594, acc5: 70.7031, elapsed_time: 1.4015s\n",
      "[0 epoch](164/3742 iteration) lr: 0.0000, loss: 6.7724, acc1: 52.3438, acc5: 69.9219, elapsed_time: 1.3921s\n",
      "[0 epoch](165/3742 iteration) lr: 0.0000, loss: 6.7569, acc1: 50.7812, acc5: 67.1875, elapsed_time: 1.3991s\n",
      "[0 epoch](166/3742 iteration) lr: 0.0000, loss: 7.0010, acc1: 30.4688, acc5: 46.4844, elapsed_time: 1.3978s\n",
      "[0 epoch](167/3742 iteration) lr: 0.0000, loss: 6.9529, acc1: 48.0469, acc5: 65.2344, elapsed_time: 1.3894s\n",
      "[0 epoch](168/3742 iteration) lr: 0.0000, loss: 6.8007, acc1: 48.8281, acc5: 69.5312, elapsed_time: 1.3980s\n",
      "[0 epoch](169/3742 iteration) lr: 0.0000, loss: 6.8178, acc1: 41.4062, acc5: 60.1562, elapsed_time: 1.4015s\n",
      "[0 epoch](170/3742 iteration) lr: 0.0000, loss: 6.9097, acc1: 43.7500, acc5: 60.9375, elapsed_time: 1.4019s\n",
      "[0 epoch](171/3742 iteration) lr: 0.0000, loss: 6.5661, acc1: 62.5000, acc5: 78.5156, elapsed_time: 1.4016s\n",
      "[0 epoch](172/3742 iteration) lr: 0.0000, loss: 6.6500, acc1: 56.2500, acc5: 70.7031, elapsed_time: 1.3956s\n",
      "[0 epoch](173/3742 iteration) lr: 0.0000, loss: 6.8393, acc1: 41.0156, acc5: 59.3750, elapsed_time: 1.4012s\n",
      "[0 epoch](174/3742 iteration) lr: 0.0000, loss: 6.9149, acc1: 41.4062, acc5: 58.5938, elapsed_time: 1.3953s\n",
      "[0 epoch](175/3742 iteration) lr: 0.0000, loss: 6.8908, acc1: 42.1875, acc5: 61.7188, elapsed_time: 1.3971s\n",
      "[0 epoch](176/3742 iteration) lr: 0.0000, loss: 6.7794, acc1: 48.8281, acc5: 65.2344, elapsed_time: 1.3978s\n",
      "[0 epoch](177/3742 iteration) lr: 0.0000, loss: 6.6488, acc1: 55.4688, acc5: 77.3438, elapsed_time: 1.3958s\n",
      "[0 epoch](178/3742 iteration) lr: 0.0000, loss: 6.8047, acc1: 44.5312, acc5: 58.9844, elapsed_time: 1.3955s\n",
      "[0 epoch](179/3742 iteration) lr: 0.0000, loss: 6.7864, acc1: 48.8281, acc5: 67.5781, elapsed_time: 1.3955s\n",
      "[0 epoch](180/3742 iteration) lr: 0.0000, loss: 6.8352, acc1: 49.6094, acc5: 66.4062, elapsed_time: 1.3977s\n",
      "[0 epoch](181/3742 iteration) lr: 0.0000, loss: 6.9008, acc1: 42.5781, acc5: 59.7656, elapsed_time: 1.4135s\n",
      "[0 epoch](182/3742 iteration) lr: 0.0000, loss: 6.9717, acc1: 42.9688, acc5: 62.1094, elapsed_time: 1.3964s\n",
      "[0 epoch](183/3742 iteration) lr: 0.0000, loss: 6.7277, acc1: 50.0000, acc5: 73.0469, elapsed_time: 1.4051s\n",
      "[0 epoch](184/3742 iteration) lr: 0.0000, loss: 6.9444, acc1: 39.0625, acc5: 53.5156, elapsed_time: 1.4098s\n",
      "[0 epoch](185/3742 iteration) lr: 0.0000, loss: 6.8395, acc1: 46.4844, acc5: 64.0625, elapsed_time: 1.4051s\n",
      "[0 epoch](186/3742 iteration) lr: 0.0000, loss: 6.9902, acc1: 40.2344, acc5: 57.4219, elapsed_time: 1.3949s\n",
      "[0 epoch](187/3742 iteration) lr: 0.0000, loss: 6.8707, acc1: 39.0625, acc5: 59.3750, elapsed_time: 1.4072s\n",
      "[0 epoch](188/3742 iteration) lr: 0.0000, loss: 6.6736, acc1: 56.6406, acc5: 69.1406, elapsed_time: 1.4060s\n",
      "[0 epoch](189/3742 iteration) lr: 0.0000, loss: 6.7701, acc1: 51.5625, acc5: 67.9688, elapsed_time: 1.4061s\n",
      "[0 epoch](190/3742 iteration) lr: 0.0000, loss: 6.7554, acc1: 57.8125, acc5: 72.2656, elapsed_time: 1.4053s\n",
      "[0 epoch](191/3742 iteration) lr: 0.0000, loss: 6.8301, acc1: 46.4844, acc5: 62.8906, elapsed_time: 1.4076s\n",
      "[0 epoch](192/3742 iteration) lr: 0.0000, loss: 6.7501, acc1: 48.0469, acc5: 70.7031, elapsed_time: 1.3973s\n",
      "[0 epoch](193/3742 iteration) lr: 0.0000, loss: 6.8781, acc1: 39.0625, acc5: 57.8125, elapsed_time: 1.3944s\n",
      "[0 epoch](194/3742 iteration) lr: 0.0000, loss: 6.7305, acc1: 53.9062, acc5: 70.3125, elapsed_time: 1.3983s\n",
      "[0 epoch](195/3742 iteration) lr: 0.0000, loss: 6.6332, acc1: 55.8594, acc5: 71.8750, elapsed_time: 1.3974s\n",
      "[0 epoch](196/3742 iteration) lr: 0.0000, loss: 6.4225, acc1: 69.5312, acc5: 85.9375, elapsed_time: 1.3925s\n",
      "[0 epoch](197/3742 iteration) lr: 0.0000, loss: 6.8130, acc1: 48.0469, acc5: 64.8438, elapsed_time: 1.3890s\n",
      "[0 epoch](198/3742 iteration) lr: 0.0000, loss: 6.8494, acc1: 39.4531, acc5: 62.1094, elapsed_time: 1.3970s\n",
      "[0 epoch](199/3742 iteration) lr: 0.0000, loss: 7.1163, acc1: 35.5469, acc5: 50.3906, elapsed_time: 1.3967s\n",
      "[0 epoch](200/3742 iteration) lr: 0.0000, loss: 6.9165, acc1: 41.4062, acc5: 62.8906, elapsed_time: 1.3921s\n",
      "[0 epoch](201/3742 iteration) lr: 0.0000, loss: 6.6065, acc1: 57.8125, acc5: 73.0469, elapsed_time: 1.3988s\n",
      "[0 epoch](202/3742 iteration) lr: 0.0000, loss: 6.9764, acc1: 37.8906, acc5: 56.2500, elapsed_time: 1.3878s\n",
      "[0 epoch](203/3742 iteration) lr: 0.0000, loss: 6.7973, acc1: 48.8281, acc5: 63.2812, elapsed_time: 1.4045s\n",
      "[0 epoch](204/3742 iteration) lr: 0.0000, loss: 6.8250, acc1: 40.2344, acc5: 56.2500, elapsed_time: 1.3907s\n",
      "[0 epoch](205/3742 iteration) lr: 0.0000, loss: 6.7629, acc1: 49.6094, acc5: 64.8438, elapsed_time: 1.3919s\n",
      "[0 epoch](206/3742 iteration) lr: 0.0000, loss: 6.7223, acc1: 46.4844, acc5: 66.7969, elapsed_time: 1.3960s\n",
      "[0 epoch](207/3742 iteration) lr: 0.0000, loss: 6.7326, acc1: 46.8750, acc5: 67.9688, elapsed_time: 1.4095s\n",
      "[0 epoch](208/3742 iteration) lr: 0.0000, loss: 6.9582, acc1: 41.4062, acc5: 57.8125, elapsed_time: 1.3982s\n",
      "[0 epoch](209/3742 iteration) lr: 0.0000, loss: 6.8734, acc1: 46.8750, acc5: 66.0156, elapsed_time: 1.4129s\n",
      "[0 epoch](210/3742 iteration) lr: 0.0000, loss: 6.8086, acc1: 44.1406, acc5: 62.1094, elapsed_time: 1.4037s\n",
      "[0 epoch](211/3742 iteration) lr: 0.0000, loss: 6.9985, acc1: 43.3594, acc5: 58.9844, elapsed_time: 1.4052s\n",
      "[0 epoch](212/3742 iteration) lr: 0.0000, loss: 6.7270, acc1: 48.0469, acc5: 68.3594, elapsed_time: 1.3930s\n",
      "[0 epoch](213/3742 iteration) lr: 0.0000, loss: 6.8283, acc1: 51.5625, acc5: 64.4531, elapsed_time: 1.4051s\n",
      "[0 epoch](214/3742 iteration) lr: 0.0000, loss: 6.9026, acc1: 39.0625, acc5: 56.2500, elapsed_time: 1.4035s\n",
      "[0 epoch](215/3742 iteration) lr: 0.0000, loss: 6.7232, acc1: 46.4844, acc5: 66.4062, elapsed_time: 1.4019s\n",
      "[0 epoch](216/3742 iteration) lr: 0.0000, loss: 6.7424, acc1: 53.9062, acc5: 66.7969, elapsed_time: 1.4044s\n",
      "[0 epoch](217/3742 iteration) lr: 0.0000, loss: 7.0412, acc1: 34.7656, acc5: 54.2969, elapsed_time: 1.3961s\n",
      "[0 epoch](218/3742 iteration) lr: 0.0000, loss: 6.7575, acc1: 50.0000, acc5: 67.5781, elapsed_time: 1.4008s\n",
      "[0 epoch](219/3742 iteration) lr: 0.0000, loss: 6.8116, acc1: 45.3125, acc5: 57.8125, elapsed_time: 1.3942s\n",
      "[0 epoch](220/3742 iteration) lr: 0.0000, loss: 6.6840, acc1: 56.6406, acc5: 75.7812, elapsed_time: 1.4020s\n",
      "[0 epoch](221/3742 iteration) lr: 0.0000, loss: 6.7318, acc1: 47.2656, acc5: 64.8438, elapsed_time: 1.3963s\n",
      "[0 epoch](222/3742 iteration) lr: 0.0000, loss: 6.6782, acc1: 57.0312, acc5: 73.0469, elapsed_time: 1.3911s\n",
      "[0 epoch](223/3742 iteration) lr: 0.0000, loss: 6.8001, acc1: 42.9688, acc5: 66.4062, elapsed_time: 1.4002s\n",
      "[0 epoch](224/3742 iteration) lr: 0.0000, loss: 6.6470, acc1: 50.3906, acc5: 69.1406, elapsed_time: 1.3996s\n",
      "[0 epoch](225/3742 iteration) lr: 0.0000, loss: 6.6675, acc1: 44.9219, acc5: 64.4531, elapsed_time: 1.4041s\n",
      "[0 epoch](226/3742 iteration) lr: 0.0000, loss: 6.6328, acc1: 57.8125, acc5: 75.0000, elapsed_time: 1.3957s\n",
      "[0 epoch](227/3742 iteration) lr: 0.0000, loss: 6.5125, acc1: 66.4062, acc5: 81.6406, elapsed_time: 1.4074s\n",
      "[0 epoch](228/3742 iteration) lr: 0.0000, loss: 6.6821, acc1: 54.2969, acc5: 67.9688, elapsed_time: 1.4002s\n",
      "[0 epoch](229/3742 iteration) lr: 0.0000, loss: 6.7755, acc1: 42.1875, acc5: 59.7656, elapsed_time: 1.3880s\n",
      "[0 epoch](230/3742 iteration) lr: 0.0000, loss: 6.8493, acc1: 48.0469, acc5: 64.0625, elapsed_time: 1.4119s\n",
      "[0 epoch](231/3742 iteration) lr: 0.0000, loss: 6.7360, acc1: 48.4375, acc5: 71.0938, elapsed_time: 1.3881s\n",
      "[0 epoch](232/3742 iteration) lr: 0.0000, loss: 6.8417, acc1: 42.5781, acc5: 64.4531, elapsed_time: 1.3942s\n",
      "[0 epoch](233/3742 iteration) lr: 0.0000, loss: 6.7017, acc1: 48.0469, acc5: 71.4844, elapsed_time: 1.4003s\n",
      "[0 epoch](234/3742 iteration) lr: 0.0000, loss: 6.5376, acc1: 65.2344, acc5: 84.7656, elapsed_time: 1.3864s\n",
      "[0 epoch](235/3742 iteration) lr: 0.0000, loss: 6.7242, acc1: 49.6094, acc5: 71.0938, elapsed_time: 1.3976s\n",
      "[0 epoch](236/3742 iteration) lr: 0.0000, loss: 6.8044, acc1: 49.2188, acc5: 66.4062, elapsed_time: 1.4055s\n",
      "[0 epoch](237/3742 iteration) lr: 0.0000, loss: 6.9053, acc1: 40.2344, acc5: 60.5469, elapsed_time: 1.4015s\n",
      "[0 epoch](238/3742 iteration) lr: 0.0000, loss: 6.8153, acc1: 38.2812, acc5: 60.5469, elapsed_time: 1.3917s\n",
      "[0 epoch](239/3742 iteration) lr: 0.0000, loss: 6.8231, acc1: 45.7031, acc5: 60.1562, elapsed_time: 1.3624s\n",
      "[0 epoch](240/3742 iteration) lr: 0.0000, loss: 6.8369, acc1: 47.2656, acc5: 66.7969, elapsed_time: 1.3955s\n",
      "[0 epoch](241/3742 iteration) lr: 0.0000, loss: 6.9330, acc1: 33.5938, acc5: 53.5156, elapsed_time: 1.4054s\n",
      "[0 epoch](242/3742 iteration) lr: 0.0000, loss: 6.8301, acc1: 44.9219, acc5: 64.0625, elapsed_time: 1.3973s\n",
      "[0 epoch](243/3742 iteration) lr: 0.0000, loss: 6.8365, acc1: 41.4062, acc5: 58.2031, elapsed_time: 1.4081s\n",
      "[0 epoch](244/3742 iteration) lr: 0.0000, loss: 6.9002, acc1: 43.3594, acc5: 62.1094, elapsed_time: 1.4024s\n",
      "[0 epoch](245/3742 iteration) lr: 0.0000, loss: 6.6315, acc1: 50.0000, acc5: 71.0938, elapsed_time: 1.3974s\n",
      "[0 epoch](246/3742 iteration) lr: 0.0000, loss: 6.9180, acc1: 34.7656, acc5: 55.4688, elapsed_time: 1.3886s\n",
      "[0 epoch](247/3742 iteration) lr: 0.0000, loss: 6.5329, acc1: 58.2031, acc5: 74.6094, elapsed_time: 1.3998s\n",
      "[0 epoch](248/3742 iteration) lr: 0.0000, loss: 6.7646, acc1: 50.0000, acc5: 66.4062, elapsed_time: 1.3880s\n",
      "[0 epoch](249/3742 iteration) lr: 0.0000, loss: 6.8077, acc1: 51.5625, acc5: 69.5312, elapsed_time: 1.4127s\n",
      "[0 epoch](250/3742 iteration) lr: 0.0000, loss: 6.9316, acc1: 39.4531, acc5: 58.2031, elapsed_time: 1.4012s\n",
      "[0 epoch](251/3742 iteration) lr: 0.0000, loss: 6.7860, acc1: 51.9531, acc5: 70.3125, elapsed_time: 1.3937s\n",
      "[0 epoch](252/3742 iteration) lr: 0.0000, loss: 6.7667, acc1: 53.9062, acc5: 70.7031, elapsed_time: 1.3881s\n",
      "[0 epoch](253/3742 iteration) lr: 0.0000, loss: 7.0371, acc1: 34.3750, acc5: 55.0781, elapsed_time: 1.3993s\n",
      "[0 epoch](254/3742 iteration) lr: 0.0000, loss: 6.9003, acc1: 39.4531, acc5: 58.5938, elapsed_time: 1.3975s\n",
      "[0 epoch](255/3742 iteration) lr: 0.0000, loss: 6.9971, acc1: 33.5938, acc5: 50.3906, elapsed_time: 1.3968s\n",
      "[0 epoch](256/3742 iteration) lr: 0.0000, loss: 6.7845, acc1: 48.8281, acc5: 61.7188, elapsed_time: 1.3944s\n",
      "[0 epoch](257/3742 iteration) lr: 0.0000, loss: 6.8500, acc1: 42.1875, acc5: 60.1562, elapsed_time: 1.3878s\n",
      "[0 epoch](258/3742 iteration) lr: 0.0000, loss: 6.9034, acc1: 42.9688, acc5: 58.2031, elapsed_time: 1.4001s\n",
      "[0 epoch](259/3742 iteration) lr: 0.0000, loss: 6.8327, acc1: 44.9219, acc5: 61.7188, elapsed_time: 1.3964s\n",
      "[0 epoch](260/3742 iteration) lr: 0.0000, loss: 6.6836, acc1: 57.0312, acc5: 73.4375, elapsed_time: 1.4052s\n",
      "[0 epoch](261/3742 iteration) lr: 0.0000, loss: 6.8625, acc1: 41.7969, acc5: 56.2500, elapsed_time: 1.3937s\n",
      "[0 epoch](262/3742 iteration) lr: 0.0000, loss: 6.7467, acc1: 55.4688, acc5: 69.1406, elapsed_time: 1.3928s\n",
      "[0 epoch](263/3742 iteration) lr: 0.0000, loss: 6.8063, acc1: 52.3438, acc5: 70.3125, elapsed_time: 1.3922s\n",
      "[0 epoch](264/3742 iteration) lr: 0.0000, loss: 6.6417, acc1: 54.6875, acc5: 73.8281, elapsed_time: 1.3966s\n",
      "[0 epoch](265/3742 iteration) lr: 0.0000, loss: 6.6218, acc1: 59.3750, acc5: 74.6094, elapsed_time: 1.3959s\n",
      "[0 epoch](266/3742 iteration) lr: 0.0000, loss: 6.6333, acc1: 55.8594, acc5: 70.7031, elapsed_time: 1.4034s\n",
      "[0 epoch](267/3742 iteration) lr: 0.0000, loss: 6.7872, acc1: 50.7812, acc5: 66.4062, elapsed_time: 1.4048s\n",
      "[0 epoch](268/3742 iteration) lr: 0.0000, loss: 6.7891, acc1: 51.9531, acc5: 71.4844, elapsed_time: 1.3995s\n",
      "[0 epoch](269/3742 iteration) lr: 0.0000, loss: 6.7668, acc1: 51.1719, acc5: 66.7969, elapsed_time: 1.3952s\n",
      "[0 epoch](270/3742 iteration) lr: 0.0000, loss: 6.5421, acc1: 62.1094, acc5: 78.5156, elapsed_time: 1.3876s\n",
      "[0 epoch](271/3742 iteration) lr: 0.0000, loss: 6.6926, acc1: 49.2188, acc5: 67.5781, elapsed_time: 1.3941s\n",
      "[0 epoch](272/3742 iteration) lr: 0.0000, loss: 6.7827, acc1: 49.6094, acc5: 67.1875, elapsed_time: 1.3937s\n",
      "[0 epoch](273/3742 iteration) lr: 0.0000, loss: 6.9460, acc1: 35.9375, acc5: 54.6875, elapsed_time: 1.3952s\n",
      "[0 epoch](274/3742 iteration) lr: 0.0000, loss: 6.7889, acc1: 52.3438, acc5: 65.6250, elapsed_time: 1.3862s\n",
      "[0 epoch](275/3742 iteration) lr: 0.0000, loss: 6.8485, acc1: 48.0469, acc5: 63.6719, elapsed_time: 1.3983s\n",
      "[0 epoch](276/3742 iteration) lr: 0.0000, loss: 6.6902, acc1: 46.4844, acc5: 67.1875, elapsed_time: 1.4125s\n",
      "[0 epoch](277/3742 iteration) lr: 0.0000, loss: 6.6111, acc1: 57.0312, acc5: 71.4844, elapsed_time: 1.3983s\n",
      "[0 epoch](278/3742 iteration) lr: 0.0000, loss: 6.8836, acc1: 46.8750, acc5: 60.9375, elapsed_time: 1.3977s\n",
      "[0 epoch](279/3742 iteration) lr: 0.0000, loss: 6.8200, acc1: 50.3906, acc5: 66.7969, elapsed_time: 1.4113s\n",
      "[0 epoch](280/3742 iteration) lr: 0.0000, loss: 6.6549, acc1: 59.3750, acc5: 76.5625, elapsed_time: 1.4002s\n",
      "[0 epoch](281/3742 iteration) lr: 0.0000, loss: 6.8211, acc1: 46.0938, acc5: 69.1406, elapsed_time: 1.3874s\n",
      "[0 epoch](282/3742 iteration) lr: 0.0000, loss: 6.8229, acc1: 51.1719, acc5: 65.6250, elapsed_time: 1.4046s\n",
      "[0 epoch](283/3742 iteration) lr: 0.0000, loss: 6.9358, acc1: 40.6250, acc5: 58.9844, elapsed_time: 1.4140s\n",
      "[0 epoch](284/3742 iteration) lr: 0.0000, loss: 6.8690, acc1: 45.3125, acc5: 62.1094, elapsed_time: 1.3890s\n",
      "[0 epoch](285/3742 iteration) lr: 0.0000, loss: 6.8639, acc1: 42.9688, acc5: 59.7656, elapsed_time: 1.3944s\n",
      "[0 epoch](286/3742 iteration) lr: 0.0000, loss: 6.8612, acc1: 46.8750, acc5: 66.7969, elapsed_time: 1.3960s\n",
      "[0 epoch](287/3742 iteration) lr: 0.0000, loss: 6.7869, acc1: 43.3594, acc5: 62.8906, elapsed_time: 1.3998s\n",
      "[0 epoch](288/3742 iteration) lr: 0.0000, loss: 6.8677, acc1: 41.7969, acc5: 63.2812, elapsed_time: 1.3971s\n",
      "[0 epoch](289/3742 iteration) lr: 0.0000, loss: 6.3212, acc1: 75.3906, acc5: 84.3750, elapsed_time: 1.4065s\n",
      "[0 epoch](290/3742 iteration) lr: 0.0000, loss: 6.7379, acc1: 46.0938, acc5: 67.9688, elapsed_time: 1.3898s\n",
      "[0 epoch](291/3742 iteration) lr: 0.0000, loss: 6.5820, acc1: 54.2969, acc5: 71.8750, elapsed_time: 1.3936s\n",
      "[0 epoch](292/3742 iteration) lr: 0.0000, loss: 6.7295, acc1: 58.2031, acc5: 73.4375, elapsed_time: 1.4033s\n",
      "[0 epoch](293/3742 iteration) lr: 0.0000, loss: 6.7106, acc1: 53.9062, acc5: 74.2188, elapsed_time: 1.4026s\n",
      "[0 epoch](294/3742 iteration) lr: 0.0000, loss: 6.7484, acc1: 49.2188, acc5: 69.9219, elapsed_time: 1.3880s\n",
      "[0 epoch](295/3742 iteration) lr: 0.0000, loss: 6.8219, acc1: 45.7031, acc5: 64.4531, elapsed_time: 1.3982s\n",
      "[0 epoch](296/3742 iteration) lr: 0.0000, loss: 6.7338, acc1: 43.3594, acc5: 63.2812, elapsed_time: 1.4012s\n",
      "[0 epoch](297/3742 iteration) lr: 0.0000, loss: 6.8096, acc1: 51.1719, acc5: 67.1875, elapsed_time: 1.4111s\n",
      "[0 epoch](298/3742 iteration) lr: 0.0000, loss: 6.8574, acc1: 40.2344, acc5: 58.2031, elapsed_time: 1.3917s\n",
      "[0 epoch](299/3742 iteration) lr: 0.0000, loss: 6.7395, acc1: 47.6562, acc5: 63.6719, elapsed_time: 1.3956s\n",
      "[0 epoch](300/3742 iteration) lr: 0.0000, loss: 6.6616, acc1: 49.6094, acc5: 68.3594, elapsed_time: 1.4077s\n",
      "[0 epoch](301/3742 iteration) lr: 0.0000, loss: 6.8350, acc1: 48.4375, acc5: 64.8438, elapsed_time: 1.4071s\n",
      "[0 epoch](302/3742 iteration) lr: 0.0000, loss: 6.9193, acc1: 37.1094, acc5: 60.1562, elapsed_time: 1.4035s\n",
      "[0 epoch](303/3742 iteration) lr: 0.0000, loss: 6.7439, acc1: 46.4844, acc5: 64.4531, elapsed_time: 1.3946s\n",
      "[0 epoch](304/3742 iteration) lr: 0.0000, loss: 6.8066, acc1: 42.5781, acc5: 61.7188, elapsed_time: 1.3924s\n",
      "[0 epoch](305/3742 iteration) lr: 0.0000, loss: 6.9888, acc1: 41.7969, acc5: 58.9844, elapsed_time: 1.4025s\n",
      "[0 epoch](306/3742 iteration) lr: 0.0000, loss: 6.6359, acc1: 48.8281, acc5: 68.7500, elapsed_time: 1.4066s\n",
      "[0 epoch](307/3742 iteration) lr: 0.0000, loss: 6.8480, acc1: 41.7969, acc5: 63.6719, elapsed_time: 1.4014s\n",
      "[0 epoch](308/3742 iteration) lr: 0.0000, loss: 6.8109, acc1: 48.4375, acc5: 66.0156, elapsed_time: 1.3935s\n",
      "[0 epoch](309/3742 iteration) lr: 0.0000, loss: 6.7623, acc1: 47.6562, acc5: 65.2344, elapsed_time: 1.3966s\n",
      "[0 epoch](310/3742 iteration) lr: 0.0000, loss: 6.9148, acc1: 40.6250, acc5: 56.2500, elapsed_time: 1.3863s\n",
      "[0 epoch](311/3742 iteration) lr: 0.0000, loss: 6.7389, acc1: 49.2188, acc5: 67.5781, elapsed_time: 1.4075s\n",
      "[0 epoch](312/3742 iteration) lr: 0.0000, loss: 6.8087, acc1: 47.2656, acc5: 69.1406, elapsed_time: 1.4015s\n",
      "[0 epoch](313/3742 iteration) lr: 0.0000, loss: 6.8020, acc1: 49.6094, acc5: 65.2344, elapsed_time: 1.3886s\n",
      "[0 epoch](314/3742 iteration) lr: 0.0000, loss: 6.7438, acc1: 58.9844, acc5: 74.6094, elapsed_time: 1.4073s\n",
      "[0 epoch](315/3742 iteration) lr: 0.0000, loss: 6.6997, acc1: 53.9062, acc5: 70.3125, elapsed_time: 1.4616s\n",
      "[0 epoch](316/3742 iteration) lr: 0.0000, loss: 6.5466, acc1: 59.3750, acc5: 76.9531, elapsed_time: 1.3959s\n",
      "[0 epoch](317/3742 iteration) lr: 0.0000, loss: 6.7243, acc1: 51.5625, acc5: 67.9688, elapsed_time: 1.4138s\n",
      "[0 epoch](318/3742 iteration) lr: 0.0000, loss: 6.6459, acc1: 54.2969, acc5: 73.4375, elapsed_time: 1.3820s\n",
      "[0 epoch](319/3742 iteration) lr: 0.0000, loss: 6.8338, acc1: 45.7031, acc5: 59.7656, elapsed_time: 1.4040s\n",
      "[0 epoch](320/3742 iteration) lr: 0.0000, loss: 6.9410, acc1: 34.7656, acc5: 54.6875, elapsed_time: 1.4042s\n",
      "[0 epoch](321/3742 iteration) lr: 0.0000, loss: 6.7969, acc1: 46.8750, acc5: 66.4062, elapsed_time: 1.4015s\n",
      "[0 epoch](322/3742 iteration) lr: 0.0000, loss: 6.6592, acc1: 51.5625, acc5: 70.3125, elapsed_time: 1.3964s\n",
      "[0 epoch](323/3742 iteration) lr: 0.0000, loss: 6.8607, acc1: 50.0000, acc5: 65.2344, elapsed_time: 1.3945s\n",
      "[0 epoch](324/3742 iteration) lr: 0.0000, loss: 6.8995, acc1: 46.0938, acc5: 60.9375, elapsed_time: 1.3966s\n",
      "[0 epoch](325/3742 iteration) lr: 0.0000, loss: 6.9046, acc1: 39.0625, acc5: 54.6875, elapsed_time: 1.4048s\n",
      "[0 epoch](326/3742 iteration) lr: 0.0000, loss: 6.7358, acc1: 46.8750, acc5: 63.2812, elapsed_time: 1.3965s\n",
      "[0 epoch](327/3742 iteration) lr: 0.0000, loss: 6.8803, acc1: 47.6562, acc5: 62.8906, elapsed_time: 1.3904s\n",
      "[0 epoch](328/3742 iteration) lr: 0.0000, loss: 6.6531, acc1: 60.1562, acc5: 77.7344, elapsed_time: 1.4071s\n",
      "[0 epoch](329/3742 iteration) lr: 0.0000, loss: 6.9094, acc1: 51.1719, acc5: 65.2344, elapsed_time: 1.3930s\n",
      "[0 epoch](330/3742 iteration) lr: 0.0000, loss: 6.8570, acc1: 38.6719, acc5: 59.7656, elapsed_time: 1.4055s\n",
      "[0 epoch](331/3742 iteration) lr: 0.0000, loss: 6.6803, acc1: 51.1719, acc5: 71.8750, elapsed_time: 1.4046s\n",
      "[0 epoch](332/3742 iteration) lr: 0.0000, loss: 6.8768, acc1: 41.0156, acc5: 58.5938, elapsed_time: 1.3972s\n",
      "[0 epoch](333/3742 iteration) lr: 0.0000, loss: 6.9263, acc1: 41.0156, acc5: 57.4219, elapsed_time: 1.4016s\n",
      "[0 epoch](334/3742 iteration) lr: 0.0000, loss: 6.8256, acc1: 44.1406, acc5: 70.7031, elapsed_time: 1.4050s\n",
      "[0 epoch](335/3742 iteration) lr: 0.0000, loss: 6.9331, acc1: 45.3125, acc5: 64.4531, elapsed_time: 1.3884s\n",
      "[0 epoch](336/3742 iteration) lr: 0.0000, loss: 6.7649, acc1: 49.2188, acc5: 62.8906, elapsed_time: 1.4084s\n",
      "[0 epoch](337/3742 iteration) lr: 0.0000, loss: 6.6654, acc1: 55.8594, acc5: 74.2188, elapsed_time: 1.3967s\n",
      "[0 epoch](338/3742 iteration) lr: 0.0000, loss: 6.9176, acc1: 44.1406, acc5: 62.1094, elapsed_time: 1.3996s\n",
      "[0 epoch](339/3742 iteration) lr: 0.0000, loss: 6.5717, acc1: 57.0312, acc5: 70.3125, elapsed_time: 1.4019s\n",
      "[0 epoch](340/3742 iteration) lr: 0.0000, loss: 6.7843, acc1: 47.2656, acc5: 64.8438, elapsed_time: 1.4135s\n",
      "[0 epoch](341/3742 iteration) lr: 0.0000, loss: 6.7383, acc1: 54.6875, acc5: 73.8281, elapsed_time: 1.3984s\n",
      "[0 epoch](342/3742 iteration) lr: 0.0000, loss: 6.8511, acc1: 42.1875, acc5: 63.2812, elapsed_time: 1.3998s\n",
      "[0 epoch](343/3742 iteration) lr: 0.0000, loss: 6.7720, acc1: 51.5625, acc5: 68.7500, elapsed_time: 1.3965s\n",
      "[0 epoch](344/3742 iteration) lr: 0.0000, loss: 7.0177, acc1: 33.9844, acc5: 53.5156, elapsed_time: 1.3942s\n",
      "[0 epoch](345/3742 iteration) lr: 0.0000, loss: 6.6695, acc1: 51.1719, acc5: 69.5312, elapsed_time: 1.3888s\n",
      "[0 epoch](346/3742 iteration) lr: 0.0000, loss: 6.8008, acc1: 37.8906, acc5: 56.6406, elapsed_time: 1.4016s\n",
      "[0 epoch](347/3742 iteration) lr: 0.0000, loss: 6.7463, acc1: 48.8281, acc5: 72.2656, elapsed_time: 1.4061s\n",
      "[0 epoch](348/3742 iteration) lr: 0.0000, loss: 6.7946, acc1: 46.8750, acc5: 69.1406, elapsed_time: 1.4049s\n",
      "[0 epoch](349/3742 iteration) lr: 0.0000, loss: 6.9697, acc1: 34.7656, acc5: 53.1250, elapsed_time: 1.3961s\n",
      "[0 epoch](350/3742 iteration) lr: 0.0000, loss: 6.4912, acc1: 63.6719, acc5: 75.3906, elapsed_time: 1.3987s\n",
      "[0 epoch](351/3742 iteration) lr: 0.0000, loss: 6.7941, acc1: 44.5312, acc5: 62.8906, elapsed_time: 1.3957s\n",
      "[0 epoch](352/3742 iteration) lr: 0.0000, loss: 6.7133, acc1: 60.1562, acc5: 74.2188, elapsed_time: 1.3975s\n",
      "[0 epoch](353/3742 iteration) lr: 0.0000, loss: 6.7768, acc1: 48.4375, acc5: 67.9688, elapsed_time: 1.4045s\n",
      "[0 epoch](354/3742 iteration) lr: 0.0000, loss: 6.6972, acc1: 52.7344, acc5: 73.4375, elapsed_time: 1.3948s\n",
      "[0 epoch](355/3742 iteration) lr: 0.0000, loss: 6.8903, acc1: 39.8438, acc5: 57.4219, elapsed_time: 1.4071s\n",
      "[0 epoch](356/3742 iteration) lr: 0.0000, loss: 6.6202, acc1: 62.8906, acc5: 76.5625, elapsed_time: 1.4089s\n",
      "[0 epoch](357/3742 iteration) lr: 0.0000, loss: 6.9487, acc1: 38.6719, acc5: 58.2031, elapsed_time: 1.3999s\n",
      "[0 epoch](358/3742 iteration) lr: 0.0000, loss: 6.8268, acc1: 44.5312, acc5: 61.7188, elapsed_time: 1.3993s\n",
      "[0 epoch](359/3742 iteration) lr: 0.0000, loss: 6.5133, acc1: 62.8906, acc5: 75.7812, elapsed_time: 1.3941s\n",
      "[0 epoch](360/3742 iteration) lr: 0.0000, loss: 6.8224, acc1: 47.6562, acc5: 71.0938, elapsed_time: 1.3924s\n",
      "[0 epoch](361/3742 iteration) lr: 0.0000, loss: 6.6145, acc1: 58.5938, acc5: 75.7812, elapsed_time: 1.4003s\n",
      "[0 epoch](362/3742 iteration) lr: 0.0000, loss: 6.5802, acc1: 60.1562, acc5: 74.2188, elapsed_time: 1.4111s\n",
      "[0 epoch](363/3742 iteration) lr: 0.0000, loss: 6.7526, acc1: 44.9219, acc5: 65.2344, elapsed_time: 1.4014s\n",
      "[0 epoch](364/3742 iteration) lr: 0.0000, loss: 7.0199, acc1: 32.0312, acc5: 46.8750, elapsed_time: 1.3991s\n",
      "[0 epoch](365/3742 iteration) lr: 0.0000, loss: 6.7102, acc1: 48.0469, acc5: 63.2812, elapsed_time: 1.4054s\n",
      "[0 epoch](366/3742 iteration) lr: 0.0000, loss: 6.6461, acc1: 64.0625, acc5: 81.2500, elapsed_time: 1.4048s\n",
      "[0 epoch](367/3742 iteration) lr: 0.0000, loss: 6.8804, acc1: 44.1406, acc5: 60.1562, elapsed_time: 1.3934s\n",
      "[0 epoch](368/3742 iteration) lr: 0.0000, loss: 6.9628, acc1: 39.4531, acc5: 57.4219, elapsed_time: 1.3919s\n",
      "[0 epoch](369/3742 iteration) lr: 0.0000, loss: 6.6801, acc1: 52.3438, acc5: 72.6562, elapsed_time: 1.3931s\n",
      "[0 epoch](370/3742 iteration) lr: 0.0000, loss: 6.9476, acc1: 37.1094, acc5: 53.1250, elapsed_time: 1.4124s\n",
      "[0 epoch](371/3742 iteration) lr: 0.0000, loss: 6.6564, acc1: 48.4375, acc5: 69.1406, elapsed_time: 1.3926s\n",
      "[0 epoch](372/3742 iteration) lr: 0.0000, loss: 6.8932, acc1: 37.5000, acc5: 57.4219, elapsed_time: 1.4077s\n",
      "[0 epoch](373/3742 iteration) lr: 0.0000, loss: 6.9379, acc1: 47.2656, acc5: 64.0625, elapsed_time: 1.3946s\n",
      "[0 epoch](374/3742 iteration) lr: 0.0000, loss: 6.6964, acc1: 55.0781, acc5: 71.4844, elapsed_time: 1.3913s\n",
      "[0 epoch](375/3742 iteration) lr: 0.0000, loss: 6.7380, acc1: 46.0938, acc5: 62.1094, elapsed_time: 1.4037s\n",
      "[0 epoch](376/3742 iteration) lr: 0.0000, loss: 6.8795, acc1: 40.6250, acc5: 59.7656, elapsed_time: 1.3936s\n",
      "[0 epoch](377/3742 iteration) lr: 0.0000, loss: 6.5684, acc1: 55.0781, acc5: 75.0000, elapsed_time: 1.4165s\n",
      "[0 epoch](378/3742 iteration) lr: 0.0000, loss: 6.8273, acc1: 48.8281, acc5: 62.5000, elapsed_time: 1.3879s\n",
      "[0 epoch](379/3742 iteration) lr: 0.0000, loss: 6.8537, acc1: 47.6562, acc5: 65.6250, elapsed_time: 1.3971s\n",
      "[0 epoch](380/3742 iteration) lr: 0.0000, loss: 6.6841, acc1: 55.0781, acc5: 70.7031, elapsed_time: 1.4088s\n",
      "[0 epoch](381/3742 iteration) lr: 0.0000, loss: 6.7470, acc1: 55.0781, acc5: 69.1406, elapsed_time: 1.3995s\n",
      "[0 epoch](382/3742 iteration) lr: 0.0000, loss: 6.7527, acc1: 55.4688, acc5: 66.4062, elapsed_time: 1.3953s\n",
      "[0 epoch](383/3742 iteration) lr: 0.0000, loss: 6.9100, acc1: 46.8750, acc5: 67.9688, elapsed_time: 1.4045s\n",
      "[0 epoch](384/3742 iteration) lr: 0.0000, loss: 6.8332, acc1: 52.3438, acc5: 73.4375, elapsed_time: 1.4110s\n",
      "[0 epoch](385/3742 iteration) lr: 0.0000, loss: 6.5507, acc1: 61.7188, acc5: 74.2188, elapsed_time: 1.3880s\n",
      "[0 epoch](386/3742 iteration) lr: 0.0000, loss: 6.6722, acc1: 50.0000, acc5: 69.5312, elapsed_time: 1.4001s\n",
      "[0 epoch](387/3742 iteration) lr: 0.0000, loss: 6.8627, acc1: 41.4062, acc5: 61.7188, elapsed_time: 1.3970s\n",
      "[0 epoch](388/3742 iteration) lr: 0.0000, loss: 7.0235, acc1: 36.7188, acc5: 55.0781, elapsed_time: 1.3978s\n",
      "[0 epoch](389/3742 iteration) lr: 0.0000, loss: 6.8359, acc1: 47.2656, acc5: 66.4062, elapsed_time: 1.3971s\n",
      "[0 epoch](390/3742 iteration) lr: 0.0000, loss: 6.7274, acc1: 44.9219, acc5: 62.5000, elapsed_time: 1.3972s\n",
      "[0 epoch](391/3742 iteration) lr: 0.0000, loss: 6.9464, acc1: 39.0625, acc5: 55.8594, elapsed_time: 1.3965s\n",
      "[0 epoch](392/3742 iteration) lr: 0.0000, loss: 6.6716, acc1: 57.0312, acc5: 74.6094, elapsed_time: 1.4012s\n",
      "[0 epoch](393/3742 iteration) lr: 0.0000, loss: 6.9080, acc1: 41.0156, acc5: 57.0312, elapsed_time: 1.4035s\n",
      "[0 epoch](394/3742 iteration) lr: 0.0000, loss: 6.6137, acc1: 49.2188, acc5: 67.5781, elapsed_time: 1.4012s\n",
      "[0 epoch](395/3742 iteration) lr: 0.0000, loss: 6.7601, acc1: 43.3594, acc5: 61.3281, elapsed_time: 1.4051s\n",
      "[0 epoch](396/3742 iteration) lr: 0.0000, loss: 6.7597, acc1: 51.5625, acc5: 66.4062, elapsed_time: 1.4019s\n",
      "[0 epoch](397/3742 iteration) lr: 0.0000, loss: 6.6180, acc1: 56.6406, acc5: 73.4375, elapsed_time: 1.4023s\n",
      "[0 epoch](398/3742 iteration) lr: 0.0000, loss: 7.0496, acc1: 38.6719, acc5: 56.6406, elapsed_time: 1.3934s\n",
      "[0 epoch](399/3742 iteration) lr: 0.0000, loss: 6.9958, acc1: 41.4062, acc5: 57.0312, elapsed_time: 1.3983s\n",
      "[0 epoch](400/3742 iteration) lr: 0.0000, loss: 6.6886, acc1: 44.5312, acc5: 63.2812, elapsed_time: 1.3959s\n",
      "[0 epoch](401/3742 iteration) lr: 0.0000, loss: 6.6181, acc1: 54.2969, acc5: 71.4844, elapsed_time: 1.3933s\n",
      "[0 epoch](402/3742 iteration) lr: 0.0000, loss: 6.8072, acc1: 45.7031, acc5: 63.2812, elapsed_time: 1.3916s\n",
      "[0 epoch](403/3742 iteration) lr: 0.0000, loss: 6.8797, acc1: 47.2656, acc5: 62.8906, elapsed_time: 1.4061s\n",
      "[0 epoch](404/3742 iteration) lr: 0.0000, loss: 6.5669, acc1: 58.9844, acc5: 70.3125, elapsed_time: 1.3953s\n",
      "[0 epoch](405/3742 iteration) lr: 0.0000, loss: 7.0596, acc1: 39.4531, acc5: 55.0781, elapsed_time: 1.4111s\n",
      "[0 epoch](406/3742 iteration) lr: 0.0000, loss: 6.7063, acc1: 53.1250, acc5: 72.2656, elapsed_time: 1.3974s\n",
      "[0 epoch](407/3742 iteration) lr: 0.0000, loss: 6.6065, acc1: 52.3438, acc5: 67.1875, elapsed_time: 1.3852s\n",
      "[0 epoch](408/3742 iteration) lr: 0.0000, loss: 6.5299, acc1: 65.6250, acc5: 77.7344, elapsed_time: 1.4005s\n",
      "[0 epoch](409/3742 iteration) lr: 0.0000, loss: 6.8137, acc1: 42.1875, acc5: 62.1094, elapsed_time: 1.4010s\n",
      "[0 epoch](410/3742 iteration) lr: 0.0000, loss: 6.8541, acc1: 48.0469, acc5: 64.4531, elapsed_time: 1.4024s\n",
      "[0 epoch](411/3742 iteration) lr: 0.0000, loss: 6.6950, acc1: 56.2500, acc5: 71.4844, elapsed_time: 1.4057s\n",
      "[0 epoch](412/3742 iteration) lr: 0.0000, loss: 6.8026, acc1: 46.4844, acc5: 68.3594, elapsed_time: 1.4069s\n",
      "[0 epoch](413/3742 iteration) lr: 0.0000, loss: 6.9465, acc1: 36.7188, acc5: 56.6406, elapsed_time: 1.3948s\n",
      "[0 epoch](414/3742 iteration) lr: 0.0000, loss: 6.9449, acc1: 35.9375, acc5: 54.2969, elapsed_time: 1.3996s\n",
      "[0 epoch](415/3742 iteration) lr: 0.0000, loss: 6.6372, acc1: 53.9062, acc5: 71.0938, elapsed_time: 1.3902s\n",
      "[0 epoch](416/3742 iteration) lr: 0.0000, loss: 6.6611, acc1: 46.0938, acc5: 65.2344, elapsed_time: 1.4180s\n",
      "[0 epoch](417/3742 iteration) lr: 0.0000, loss: 6.8861, acc1: 38.6719, acc5: 58.5938, elapsed_time: 1.3875s\n",
      "[0 epoch](418/3742 iteration) lr: 0.0000, loss: 6.6619, acc1: 49.6094, acc5: 68.7500, elapsed_time: 1.3913s\n",
      "[0 epoch](419/3742 iteration) lr: 0.0000, loss: 6.5414, acc1: 58.9844, acc5: 78.1250, elapsed_time: 1.4093s\n",
      "[0 epoch](420/3742 iteration) lr: 0.0000, loss: 6.6939, acc1: 58.9844, acc5: 73.0469, elapsed_time: 1.3938s\n",
      "[0 epoch](421/3742 iteration) lr: 0.0000, loss: 6.9237, acc1: 37.8906, acc5: 55.8594, elapsed_time: 1.3982s\n",
      "[0 epoch](422/3742 iteration) lr: 0.0000, loss: 6.6526, acc1: 55.0781, acc5: 72.6562, elapsed_time: 1.3982s\n",
      "[0 epoch](423/3742 iteration) lr: 0.0000, loss: 6.8188, acc1: 43.3594, acc5: 66.4062, elapsed_time: 1.3973s\n",
      "[0 epoch](424/3742 iteration) lr: 0.0000, loss: 6.4802, acc1: 60.9375, acc5: 82.0312, elapsed_time: 1.4049s\n",
      "[0 epoch](425/3742 iteration) lr: 0.0000, loss: 6.8827, acc1: 44.9219, acc5: 59.3750, elapsed_time: 1.3978s\n",
      "[0 epoch](426/3742 iteration) lr: 0.0000, loss: 6.7562, acc1: 48.0469, acc5: 66.0156, elapsed_time: 1.4005s\n",
      "[0 epoch](427/3742 iteration) lr: 0.0000, loss: 6.7156, acc1: 44.5312, acc5: 65.2344, elapsed_time: 1.3968s\n",
      "[0 epoch](428/3742 iteration) lr: 0.0000, loss: 6.9026, acc1: 42.9688, acc5: 58.2031, elapsed_time: 1.4091s\n",
      "[0 epoch](429/3742 iteration) lr: 0.0000, loss: 6.8885, acc1: 41.4062, acc5: 63.6719, elapsed_time: 1.3914s\n",
      "[0 epoch](430/3742 iteration) lr: 0.0000, loss: 6.8268, acc1: 42.1875, acc5: 64.4531, elapsed_time: 1.4008s\n",
      "[0 epoch](431/3742 iteration) lr: 0.0000, loss: 6.7884, acc1: 46.0938, acc5: 63.6719, elapsed_time: 1.4023s\n",
      "[0 epoch](432/3742 iteration) lr: 0.0000, loss: 6.8241, acc1: 39.4531, acc5: 58.5938, elapsed_time: 1.4102s\n",
      "[0 epoch](433/3742 iteration) lr: 0.0000, loss: 6.8621, acc1: 50.0000, acc5: 66.7969, elapsed_time: 1.4035s\n",
      "[0 epoch](434/3742 iteration) lr: 0.0000, loss: 6.8649, acc1: 46.8750, acc5: 68.3594, elapsed_time: 1.4016s\n",
      "[0 epoch](435/3742 iteration) lr: 0.0000, loss: 6.8493, acc1: 36.7188, acc5: 57.0312, elapsed_time: 1.4029s\n",
      "[0 epoch](436/3742 iteration) lr: 0.0000, loss: 6.7061, acc1: 53.9062, acc5: 73.4375, elapsed_time: 1.4063s\n",
      "[0 epoch](437/3742 iteration) lr: 0.0000, loss: 6.9309, acc1: 41.4062, acc5: 55.4688, elapsed_time: 1.4094s\n",
      "[0 epoch](438/3742 iteration) lr: 0.0000, loss: 6.8130, acc1: 49.2188, acc5: 62.1094, elapsed_time: 1.4067s\n",
      "[0 epoch](439/3742 iteration) lr: 0.0000, loss: 6.7030, acc1: 55.8594, acc5: 75.7812, elapsed_time: 1.3987s\n",
      "[0 epoch](440/3742 iteration) lr: 0.0000, loss: 6.9162, acc1: 38.2812, acc5: 56.2500, elapsed_time: 1.4057s\n",
      "[0 epoch](441/3742 iteration) lr: 0.0000, loss: 6.7085, acc1: 46.4844, acc5: 66.4062, elapsed_time: 1.3947s\n",
      "[0 epoch](442/3742 iteration) lr: 0.0000, loss: 6.9864, acc1: 43.3594, acc5: 63.6719, elapsed_time: 1.4134s\n",
      "[0 epoch](443/3742 iteration) lr: 0.0000, loss: 6.9432, acc1: 37.5000, acc5: 59.3750, elapsed_time: 1.3900s\n",
      "[0 epoch](444/3742 iteration) lr: 0.0000, loss: 6.9269, acc1: 46.0938, acc5: 63.6719, elapsed_time: 1.4037s\n",
      "[0 epoch](445/3742 iteration) lr: 0.0000, loss: 6.8094, acc1: 41.4062, acc5: 58.5938, elapsed_time: 1.3952s\n",
      "[0 epoch](446/3742 iteration) lr: 0.0000, loss: 6.9773, acc1: 35.9375, acc5: 55.4688, elapsed_time: 1.3887s\n",
      "[0 epoch](447/3742 iteration) lr: 0.0000, loss: 6.8951, acc1: 35.5469, acc5: 58.9844, elapsed_time: 1.4028s\n",
      "[0 epoch](448/3742 iteration) lr: 0.0000, loss: 6.6422, acc1: 52.7344, acc5: 67.1875, elapsed_time: 1.3884s\n",
      "[0 epoch](449/3742 iteration) lr: 0.0000, loss: 6.6974, acc1: 53.1250, acc5: 68.7500, elapsed_time: 1.4122s\n",
      "[0 epoch](450/3742 iteration) lr: 0.0000, loss: 6.8738, acc1: 50.7812, acc5: 66.7969, elapsed_time: 1.3975s\n",
      "[0 epoch](451/3742 iteration) lr: 0.0000, loss: 6.7367, acc1: 48.0469, acc5: 63.6719, elapsed_time: 1.3942s\n",
      "[0 epoch](452/3742 iteration) lr: 0.0000, loss: 6.7867, acc1: 46.4844, acc5: 70.7031, elapsed_time: 1.4122s\n",
      "[0 epoch](453/3742 iteration) lr: 0.0000, loss: 6.8272, acc1: 53.1250, acc5: 70.7031, elapsed_time: 1.3952s\n",
      "[0 epoch](454/3742 iteration) lr: 0.0000, loss: 6.7833, acc1: 48.0469, acc5: 65.6250, elapsed_time: 1.3998s\n",
      "[0 epoch](455/3742 iteration) lr: 0.0000, loss: 7.0040, acc1: 35.5469, acc5: 55.8594, elapsed_time: 1.3965s\n",
      "[0 epoch](456/3742 iteration) lr: 0.0000, loss: 6.7764, acc1: 51.1719, acc5: 69.5312, elapsed_time: 1.3959s\n",
      "[0 epoch](457/3742 iteration) lr: 0.0000, loss: 6.8354, acc1: 45.3125, acc5: 61.7188, elapsed_time: 1.3973s\n",
      "[0 epoch](458/3742 iteration) lr: 0.0000, loss: 6.7887, acc1: 39.4531, acc5: 63.2812, elapsed_time: 1.3921s\n",
      "[0 epoch](459/3742 iteration) lr: 0.0000, loss: 6.9889, acc1: 39.8438, acc5: 57.0312, elapsed_time: 1.3905s\n",
      "[0 epoch](460/3742 iteration) lr: 0.0000, loss: 6.8009, acc1: 47.6562, acc5: 64.0625, elapsed_time: 1.4170s\n",
      "[0 epoch](461/3742 iteration) lr: 0.0000, loss: 6.9202, acc1: 49.2188, acc5: 64.4531, elapsed_time: 1.3781s\n",
      "[0 epoch](462/3742 iteration) lr: 0.0000, loss: 6.6935, acc1: 46.0938, acc5: 67.5781, elapsed_time: 1.3939s\n",
      "[0 epoch](463/3742 iteration) lr: 0.0000, loss: 6.7467, acc1: 51.1719, acc5: 69.9219, elapsed_time: 1.4074s\n",
      "[0 epoch](464/3742 iteration) lr: 0.0000, loss: 7.1005, acc1: 31.2500, acc5: 48.8281, elapsed_time: 1.3914s\n",
      "[0 epoch](465/3742 iteration) lr: 0.0000, loss: 6.8281, acc1: 43.7500, acc5: 62.5000, elapsed_time: 1.4059s\n",
      "[0 epoch](466/3742 iteration) lr: 0.0000, loss: 6.8821, acc1: 42.5781, acc5: 63.6719, elapsed_time: 1.4058s\n",
      "[0 epoch](467/3742 iteration) lr: 0.0000, loss: 6.8344, acc1: 45.3125, acc5: 64.0625, elapsed_time: 1.3963s\n",
      "[0 epoch](468/3742 iteration) lr: 0.0000, loss: 6.6167, acc1: 62.1094, acc5: 78.9062, elapsed_time: 1.4129s\n",
      "[0 epoch](469/3742 iteration) lr: 0.0000, loss: 6.9858, acc1: 35.1562, acc5: 57.8125, elapsed_time: 1.4005s\n",
      "[0 epoch](470/3742 iteration) lr: 0.0000, loss: 6.7229, acc1: 51.1719, acc5: 71.4844, elapsed_time: 1.3900s\n",
      "[0 epoch](471/3742 iteration) lr: 0.0000, loss: 6.9223, acc1: 39.8438, acc5: 58.5938, elapsed_time: 1.3968s\n",
      "[0 epoch](472/3742 iteration) lr: 0.0000, loss: 6.8771, acc1: 39.0625, acc5: 56.2500, elapsed_time: 1.3940s\n",
      "[0 epoch](473/3742 iteration) lr: 0.0000, loss: 6.6593, acc1: 57.0312, acc5: 74.2188, elapsed_time: 1.3990s\n",
      "[0 epoch](474/3742 iteration) lr: 0.0000, loss: 6.8629, acc1: 48.0469, acc5: 58.2031, elapsed_time: 1.3993s\n",
      "[0 epoch](475/3742 iteration) lr: 0.0000, loss: 6.9450, acc1: 41.4062, acc5: 54.6875, elapsed_time: 1.4073s\n",
      "[0 epoch](476/3742 iteration) lr: 0.0000, loss: 6.8087, acc1: 44.5312, acc5: 60.9375, elapsed_time: 1.3871s\n",
      "[0 epoch](477/3742 iteration) lr: 0.0000, loss: 6.7917, acc1: 55.0781, acc5: 69.9219, elapsed_time: 1.3914s\n",
      "[0 epoch](478/3742 iteration) lr: 0.0000, loss: 6.7815, acc1: 51.1719, acc5: 63.6719, elapsed_time: 1.3874s\n",
      "[0 epoch](479/3742 iteration) lr: 0.0000, loss: 7.0278, acc1: 35.5469, acc5: 51.5625, elapsed_time: 1.3914s\n",
      "[0 epoch](480/3742 iteration) lr: 0.0000, loss: 6.6612, acc1: 51.1719, acc5: 68.7500, elapsed_time: 1.3955s\n",
      "[0 epoch](481/3742 iteration) lr: 0.0000, loss: 6.7883, acc1: 42.1875, acc5: 61.3281, elapsed_time: 1.4021s\n",
      "[0 epoch](482/3742 iteration) lr: 0.0000, loss: 6.7835, acc1: 47.2656, acc5: 66.4062, elapsed_time: 1.4048s\n",
      "[0 epoch](483/3742 iteration) lr: 0.0000, loss: 6.7855, acc1: 54.6875, acc5: 72.2656, elapsed_time: 1.4021s\n",
      "[0 epoch](484/3742 iteration) lr: 0.0000, loss: 6.7250, acc1: 52.3438, acc5: 65.6250, elapsed_time: 1.3944s\n",
      "[0 epoch](485/3742 iteration) lr: 0.0000, loss: 6.7604, acc1: 51.1719, acc5: 67.5781, elapsed_time: 1.4074s\n",
      "[0 epoch](486/3742 iteration) lr: 0.0000, loss: 6.9626, acc1: 42.5781, acc5: 65.6250, elapsed_time: 1.3967s\n",
      "[0 epoch](487/3742 iteration) lr: 0.0000, loss: 6.8229, acc1: 46.4844, acc5: 66.4062, elapsed_time: 1.4013s\n",
      "[0 epoch](488/3742 iteration) lr: 0.0000, loss: 6.9638, acc1: 40.6250, acc5: 55.8594, elapsed_time: 1.3987s\n",
      "[0 epoch](489/3742 iteration) lr: 0.0000, loss: 6.9312, acc1: 37.8906, acc5: 56.2500, elapsed_time: 1.3951s\n",
      "[0 epoch](490/3742 iteration) lr: 0.0000, loss: 6.7171, acc1: 48.8281, acc5: 68.3594, elapsed_time: 1.3987s\n",
      "[0 epoch](491/3742 iteration) lr: 0.0000, loss: 6.8121, acc1: 44.9219, acc5: 63.6719, elapsed_time: 1.3971s\n",
      "[0 epoch](492/3742 iteration) lr: 0.0000, loss: 7.0495, acc1: 41.0156, acc5: 59.3750, elapsed_time: 1.4037s\n",
      "[0 epoch](493/3742 iteration) lr: 0.0000, loss: 6.9451, acc1: 33.2031, acc5: 53.1250, elapsed_time: 1.3887s\n",
      "[0 epoch](494/3742 iteration) lr: 0.0000, loss: 6.7111, acc1: 55.8594, acc5: 67.9688, elapsed_time: 1.3981s\n",
      "[0 epoch](495/3742 iteration) lr: 0.0000, loss: 6.7642, acc1: 55.0781, acc5: 71.8750, elapsed_time: 1.3993s\n",
      "[0 epoch](496/3742 iteration) lr: 0.0000, loss: 6.5193, acc1: 53.5156, acc5: 71.4844, elapsed_time: 1.3938s\n",
      "[0 epoch](497/3742 iteration) lr: 0.0000, loss: 6.8207, acc1: 49.2188, acc5: 67.9688, elapsed_time: 1.4017s\n",
      "[0 epoch](498/3742 iteration) lr: 0.0000, loss: 6.6420, acc1: 57.4219, acc5: 78.5156, elapsed_time: 1.3960s\n",
      "[0 epoch](499/3742 iteration) lr: 0.0000, loss: 6.7783, acc1: 47.2656, acc5: 67.5781, elapsed_time: 1.4018s\n",
      "[0 epoch](500/3742 iteration) lr: 0.0000, loss: 6.8202, acc1: 41.7969, acc5: 61.3281, elapsed_time: 1.3997s\n",
      "[0 epoch](501/3742 iteration) lr: 0.0000, loss: 7.0462, acc1: 35.5469, acc5: 53.9062, elapsed_time: 1.3927s\n",
      "[0 epoch](502/3742 iteration) lr: 0.0000, loss: 6.8072, acc1: 46.4844, acc5: 62.1094, elapsed_time: 1.3907s\n",
      "[0 epoch](503/3742 iteration) lr: 0.0000, loss: 6.8245, acc1: 40.6250, acc5: 62.8906, elapsed_time: 1.3969s\n",
      "[0 epoch](504/3742 iteration) lr: 0.0000, loss: 6.8268, acc1: 44.9219, acc5: 60.1562, elapsed_time: 1.4108s\n",
      "[0 epoch](505/3742 iteration) lr: 0.0000, loss: 6.7392, acc1: 52.3438, acc5: 63.6719, elapsed_time: 1.4051s\n",
      "[0 epoch](506/3742 iteration) lr: 0.0000, loss: 6.4942, acc1: 69.9219, acc5: 80.4688, elapsed_time: 1.3928s\n",
      "[0 epoch](507/3742 iteration) lr: 0.0000, loss: 6.7363, acc1: 51.5625, acc5: 67.9688, elapsed_time: 1.4024s\n",
      "[0 epoch](508/3742 iteration) lr: 0.0000, loss: 6.6641, acc1: 47.6562, acc5: 65.2344, elapsed_time: 1.4020s\n",
      "[0 epoch](509/3742 iteration) lr: 0.0000, loss: 6.6218, acc1: 51.1719, acc5: 71.8750, elapsed_time: 1.3912s\n",
      "[0 epoch](510/3742 iteration) lr: 0.0000, loss: 6.7394, acc1: 55.0781, acc5: 69.1406, elapsed_time: 1.4035s\n",
      "[0 epoch](511/3742 iteration) lr: 0.0000, loss: 6.7406, acc1: 46.8750, acc5: 64.4531, elapsed_time: 1.3911s\n",
      "[0 epoch](512/3742 iteration) lr: 0.0000, loss: 6.7414, acc1: 56.6406, acc5: 73.8281, elapsed_time: 1.4072s\n",
      "[0 epoch](513/3742 iteration) lr: 0.0000, loss: 6.7253, acc1: 52.3438, acc5: 71.0938, elapsed_time: 1.4058s\n",
      "[0 epoch](514/3742 iteration) lr: 0.0000, loss: 6.8510, acc1: 44.9219, acc5: 62.1094, elapsed_time: 1.4099s\n",
      "[0 epoch](515/3742 iteration) lr: 0.0000, loss: 6.8664, acc1: 41.0156, acc5: 57.4219, elapsed_time: 1.3899s\n",
      "[0 epoch](516/3742 iteration) lr: 0.0000, loss: 6.6377, acc1: 60.1562, acc5: 75.0000, elapsed_time: 1.3982s\n",
      "[0 epoch](517/3742 iteration) lr: 0.0000, loss: 6.8725, acc1: 42.9688, acc5: 57.8125, elapsed_time: 1.4087s\n",
      "[0 epoch](518/3742 iteration) lr: 0.0000, loss: 6.7464, acc1: 55.0781, acc5: 73.0469, elapsed_time: 1.4026s\n",
      "[0 epoch](519/3742 iteration) lr: 0.0000, loss: 6.6253, acc1: 56.2500, acc5: 74.6094, elapsed_time: 1.4087s\n",
      "[0 epoch](520/3742 iteration) lr: 0.0000, loss: 6.8203, acc1: 46.0938, acc5: 59.3750, elapsed_time: 1.3921s\n",
      "[0 epoch](521/3742 iteration) lr: 0.0000, loss: 6.7460, acc1: 51.9531, acc5: 69.1406, elapsed_time: 1.4098s\n",
      "[0 epoch](522/3742 iteration) lr: 0.0000, loss: 6.8805, acc1: 46.8750, acc5: 63.2812, elapsed_time: 1.3984s\n",
      "[0 epoch](523/3742 iteration) lr: 0.0000, loss: 6.8566, acc1: 43.7500, acc5: 64.0625, elapsed_time: 1.3980s\n",
      "[0 epoch](524/3742 iteration) lr: 0.0000, loss: 6.8110, acc1: 51.1719, acc5: 68.7500, elapsed_time: 1.3956s\n",
      "[0 epoch](525/3742 iteration) lr: 0.0000, loss: 6.9160, acc1: 47.2656, acc5: 59.7656, elapsed_time: 1.3918s\n",
      "[0 epoch](526/3742 iteration) lr: 0.0000, loss: 6.7871, acc1: 43.7500, acc5: 59.7656, elapsed_time: 1.4009s\n",
      "[0 epoch](527/3742 iteration) lr: 0.0000, loss: 6.8050, acc1: 49.2188, acc5: 67.5781, elapsed_time: 1.4065s\n",
      "[0 epoch](528/3742 iteration) lr: 0.0000, loss: 6.8220, acc1: 45.3125, acc5: 62.1094, elapsed_time: 1.4013s\n",
      "[0 epoch](529/3742 iteration) lr: 0.0000, loss: 6.9598, acc1: 37.8906, acc5: 53.9062, elapsed_time: 1.4073s\n",
      "[0 epoch](530/3742 iteration) lr: 0.0000, loss: 6.9954, acc1: 37.8906, acc5: 54.2969, elapsed_time: 1.4068s\n",
      "[0 epoch](531/3742 iteration) lr: 0.0000, loss: 6.8034, acc1: 41.7969, acc5: 60.5469, elapsed_time: 1.3912s\n",
      "[0 epoch](532/3742 iteration) lr: 0.0000, loss: 6.5804, acc1: 57.4219, acc5: 77.3438, elapsed_time: 1.4092s\n",
      "[0 epoch](533/3742 iteration) lr: 0.0000, loss: 6.9575, acc1: 40.6250, acc5: 58.9844, elapsed_time: 1.3991s\n",
      "[0 epoch](534/3742 iteration) lr: 0.0000, loss: 6.6211, acc1: 52.7344, acc5: 71.0938, elapsed_time: 1.3921s\n",
      "[0 epoch](535/3742 iteration) lr: 0.0000, loss: 6.7416, acc1: 51.5625, acc5: 71.8750, elapsed_time: 1.4018s\n",
      "[0 epoch](536/3742 iteration) lr: 0.0000, loss: 6.7673, acc1: 51.9531, acc5: 69.9219, elapsed_time: 1.4017s\n",
      "[0 epoch](537/3742 iteration) lr: 0.0000, loss: 6.9079, acc1: 42.5781, acc5: 64.8438, elapsed_time: 1.3865s\n",
      "[0 epoch](538/3742 iteration) lr: 0.0000, loss: 6.5820, acc1: 53.5156, acc5: 75.0000, elapsed_time: 1.4013s\n",
      "[0 epoch](539/3742 iteration) lr: 0.0000, loss: 6.9046, acc1: 42.5781, acc5: 62.1094, elapsed_time: 1.4059s\n",
      "[0 epoch](540/3742 iteration) lr: 0.0000, loss: 6.8679, acc1: 46.4844, acc5: 60.1562, elapsed_time: 1.3977s\n",
      "[0 epoch](541/3742 iteration) lr: 0.0000, loss: 6.6472, acc1: 56.6406, acc5: 72.2656, elapsed_time: 1.3956s\n",
      "[0 epoch](542/3742 iteration) lr: 0.0000, loss: 6.8129, acc1: 48.4375, acc5: 62.8906, elapsed_time: 1.4062s\n",
      "[0 epoch](543/3742 iteration) lr: 0.0000, loss: 6.6271, acc1: 56.2500, acc5: 76.5625, elapsed_time: 1.3958s\n",
      "[0 epoch](544/3742 iteration) lr: 0.0000, loss: 6.7925, acc1: 50.3906, acc5: 68.3594, elapsed_time: 1.4099s\n",
      "[0 epoch](545/3742 iteration) lr: 0.0000, loss: 6.8267, acc1: 44.1406, acc5: 64.0625, elapsed_time: 1.3884s\n",
      "[0 epoch](546/3742 iteration) lr: 0.0000, loss: 6.7694, acc1: 44.5312, acc5: 69.1406, elapsed_time: 1.4127s\n",
      "[0 epoch](547/3742 iteration) lr: 0.0000, loss: 6.6178, acc1: 51.5625, acc5: 71.0938, elapsed_time: 1.3856s\n",
      "[0 epoch](548/3742 iteration) lr: 0.0000, loss: 6.6402, acc1: 58.2031, acc5: 75.0000, elapsed_time: 1.4118s\n",
      "[0 epoch](549/3742 iteration) lr: 0.0000, loss: 6.5959, acc1: 55.8594, acc5: 74.6094, elapsed_time: 1.4002s\n",
      "[0 epoch](550/3742 iteration) lr: 0.0000, loss: 6.9021, acc1: 43.7500, acc5: 64.8438, elapsed_time: 1.3941s\n",
      "[0 epoch](551/3742 iteration) lr: 0.0000, loss: 6.7204, acc1: 44.1406, acc5: 63.6719, elapsed_time: 1.4032s\n",
      "[0 epoch](552/3742 iteration) lr: 0.0000, loss: 6.8639, acc1: 43.7500, acc5: 60.1562, elapsed_time: 1.3940s\n",
      "[0 epoch](553/3742 iteration) lr: 0.0000, loss: 6.8875, acc1: 44.9219, acc5: 60.5469, elapsed_time: 1.3897s\n",
      "[0 epoch](554/3742 iteration) lr: 0.0000, loss: 6.7052, acc1: 51.9531, acc5: 63.6719, elapsed_time: 1.4114s\n",
      "[0 epoch](555/3742 iteration) lr: 0.0000, loss: 6.7072, acc1: 54.6875, acc5: 66.7969, elapsed_time: 1.4200s\n",
      "[0 epoch](556/3742 iteration) lr: 0.0000, loss: 6.9050, acc1: 45.3125, acc5: 62.1094, elapsed_time: 1.3813s\n",
      "[0 epoch](557/3742 iteration) lr: 0.0000, loss: 6.7957, acc1: 46.4844, acc5: 64.8438, elapsed_time: 1.4060s\n",
      "[0 epoch](558/3742 iteration) lr: 0.0000, loss: 6.6989, acc1: 51.1719, acc5: 64.0625, elapsed_time: 1.3996s\n",
      "[0 epoch](559/3742 iteration) lr: 0.0000, loss: 6.7037, acc1: 55.0781, acc5: 74.2188, elapsed_time: 1.4095s\n",
      "[0 epoch](560/3742 iteration) lr: 0.0000, loss: 6.8286, acc1: 46.8750, acc5: 67.9688, elapsed_time: 1.4051s\n",
      "[0 epoch](561/3742 iteration) lr: 0.0000, loss: 6.5860, acc1: 59.3750, acc5: 78.1250, elapsed_time: 1.3887s\n",
      "[0 epoch](562/3742 iteration) lr: 0.0000, loss: 6.9198, acc1: 46.0938, acc5: 66.7969, elapsed_time: 1.4004s\n",
      "[0 epoch](563/3742 iteration) lr: 0.0000, loss: 6.7640, acc1: 52.3438, acc5: 66.0156, elapsed_time: 1.4142s\n",
      "[0 epoch](564/3742 iteration) lr: 0.0000, loss: 6.8366, acc1: 47.6562, acc5: 66.0156, elapsed_time: 1.3977s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m data_q \u001b[38;5;241m=\u001b[39m data_q\u001b[38;5;241m.\u001b[39mview(view_size)\n\u001b[1;32m     56\u001b[0m data_k \u001b[38;5;241m=\u001b[39m data_k\u001b[38;5;241m.\u001b[39mview(view_size) \n\u001b[0;32m---> 58\u001b[0m output, target \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_k\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m     60\u001b[0m acc1, acc5 \u001b[38;5;241m=\u001b[39m accuracy(output, target, topk\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m, in \u001b[0;36mVLLIP.forward\u001b[0;34m(self, img_q, img_k)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_q, img_k): \u001b[38;5;66;03m#SCRL과 동일함\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# bs, 512\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mnormalize(embeddings, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# bs, 512\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# get q and k index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 73\u001b[0m, in \u001b[0;36mVLLIP_vit_encoder.forward\u001b[0;34m(self, images, type)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#CLIP ViT\u001b[39;00m\n\u001b[1;32m     72\u001b[0m visual_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip(images\u001b[38;5;241m.\u001b[39mcuda(), mask_list\u001b[38;5;241m.\u001b[39mcuda(), masking_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_masking\u001b[39m\u001b[38;5;124m'\u001b[39m, masking_block\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m visual_features \u001b[38;5;241m=\u001b[39m \u001b[43mvisual_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m visual_features\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import models.backbones.visual.resnet as resnet\n",
    "from models.core.SCRL_MoCo import SCRL\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.init(project='VLLIP', entity='nstar1125')\n",
    "wandb.run.name = 'test_run-1'\n",
    "wandb.run.save()\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "model = VLLIP(\n",
    "                dino=dino,\n",
    "                sam=sam,\n",
    "                clip=clip_vit,\n",
    "                type = 'train'\n",
    "            ).cuda()\n",
    "\n",
    "model.train()\n",
    "model.clip.train()\n",
    "optimizer = torch.optim.SGD(model.clip.parameters(), cfg['optim']['lr'],\n",
    "                                    momentum=cfg['optim']['momentum'],\n",
    "                                    weight_decay=cfg['optim']['wd'])\n",
    "\"\"\"\n",
    "o_model = SCRL(\n",
    "            base_encoder                = resnet.encoder_resnet50,\n",
    "            dim                         = cfg['MoCo']['dim'], \n",
    "            K                           = cfg['MoCo']['k'], \n",
    "            m                           = cfg['MoCo']['m'], \n",
    "            T                           = cfg['MoCo']['t'], \n",
    "            mlp                         = True, \n",
    "            encoder_pretrained_path     = \"./pretrain/resnet50-19c8e357.pth\",\n",
    "            multi_positive              = cfg['MoCo']['multi_positive'],\n",
    "            positive_selection          = cfg['model']['Positive_Selection'],\n",
    "            cluster_num                 = cfg['model']['cluster_num'],\n",
    "            soft_gamma                  = cfg['model']['soft_gamma'],\n",
    "            ).cuda()\n",
    "o_model.train()\n",
    "optimizer = torch.optim.SGD(o_model.parameters(), cfg['optim']['lr'],\n",
    "                                    momentum=cfg['optim']['momentum'],\n",
    "                                    weight_decay=cfg['optim']['wd'])\n",
    "\"\"\"\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(int(torch.cuda.memory_allocated(device='cuda')/1024**2),\"MB\") #DEBUG\n",
    "\n",
    "for epoch in range(4):\n",
    "    #for i, data in tqdm(enumerate(train_loader),total=len(train_loader),ncols=100, position=0, leave=True):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        pivot = time.time()\n",
    "        view_size = (-1, 3 * cfg['data']['frame_size'], 224, 224)\n",
    "        data_q = data[0].cuda(torch.cuda.current_device(), non_blocking=True)\n",
    "        data_k = data[1].cuda(torch.cuda.current_device(), non_blocking=True)\n",
    "        data_q = data_q.view(view_size)\n",
    "        data_k = data_k.view(view_size) \n",
    "    \n",
    "        output, target = model(data_q, data_k) \n",
    "        loss = criterion(output, target)\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        loss.requires_grad_(True)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"[{epoch} epoch]({i}/{len(train_loader)} iteration) lr: {optimizer.param_groups[0]['lr']:.4f}, loss: {loss:.4f}, acc1: {acc1[0]:.4f}, acc5: {acc5[0]:.4f}, elapsed_time: {(time.time()-pivot):.4f}s\")\n",
    "        wandb.log({\n",
    "            \"lr\": optimizer.param_groups[0]['lr'],\n",
    "            \"loss\": loss,\n",
    "            \"acc1\": acc1,\n",
    "            \"acc5\": acc5\n",
    "        })\n",
    "        pivot = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.positional_embedding\n",
      "model.text_projection\n",
      "model.logit_scale\n",
      "model.visual.conv1.weight\n",
      "model.visual.bn1.weight\n",
      "model.visual.bn1.bias\n",
      "model.visual.conv2.weight\n",
      "model.visual.bn2.weight\n",
      "model.visual.bn2.bias\n",
      "model.visual.conv3.weight\n",
      "model.visual.bn3.weight\n",
      "model.visual.bn3.bias\n",
      "model.visual.layer1.0.conv1.weight\n",
      "model.visual.layer1.0.bn1.weight\n",
      "model.visual.layer1.0.bn1.bias\n",
      "model.visual.layer1.0.conv2.weight\n",
      "model.visual.layer1.0.bn2.weight\n",
      "model.visual.layer1.0.bn2.bias\n",
      "model.visual.layer1.0.conv3.weight\n",
      "model.visual.layer1.0.bn3.weight\n",
      "model.visual.layer1.0.bn3.bias\n",
      "model.visual.layer1.0.downsample.0.weight\n",
      "model.visual.layer1.0.downsample.1.weight\n",
      "model.visual.layer1.0.downsample.1.bias\n",
      "model.visual.layer1.1.conv1.weight\n",
      "model.visual.layer1.1.bn1.weight\n",
      "model.visual.layer1.1.bn1.bias\n",
      "model.visual.layer1.1.conv2.weight\n",
      "model.visual.layer1.1.bn2.weight\n",
      "model.visual.layer1.1.bn2.bias\n",
      "model.visual.layer1.1.conv3.weight\n",
      "model.visual.layer1.1.bn3.weight\n",
      "model.visual.layer1.1.bn3.bias\n",
      "model.visual.layer1.2.conv1.weight\n",
      "model.visual.layer1.2.bn1.weight\n",
      "model.visual.layer1.2.bn1.bias\n",
      "model.visual.layer1.2.conv2.weight\n",
      "model.visual.layer1.2.bn2.weight\n",
      "model.visual.layer1.2.bn2.bias\n",
      "model.visual.layer1.2.conv3.weight\n",
      "model.visual.layer1.2.bn3.weight\n",
      "model.visual.layer1.2.bn3.bias\n",
      "model.visual.layer2.0.conv1.weight\n",
      "model.visual.layer2.0.bn1.weight\n",
      "model.visual.layer2.0.bn1.bias\n",
      "model.visual.layer2.0.conv2.weight\n",
      "model.visual.layer2.0.bn2.weight\n",
      "model.visual.layer2.0.bn2.bias\n",
      "model.visual.layer2.0.conv3.weight\n",
      "model.visual.layer2.0.bn3.weight\n",
      "model.visual.layer2.0.bn3.bias\n",
      "model.visual.layer2.0.downsample.0.weight\n",
      "model.visual.layer2.0.downsample.1.weight\n",
      "model.visual.layer2.0.downsample.1.bias\n",
      "model.visual.layer2.1.conv1.weight\n",
      "model.visual.layer2.1.bn1.weight\n",
      "model.visual.layer2.1.bn1.bias\n",
      "model.visual.layer2.1.conv2.weight\n",
      "model.visual.layer2.1.bn2.weight\n",
      "model.visual.layer2.1.bn2.bias\n",
      "model.visual.layer2.1.conv3.weight\n",
      "model.visual.layer2.1.bn3.weight\n",
      "model.visual.layer2.1.bn3.bias\n",
      "model.visual.layer2.2.conv1.weight\n",
      "model.visual.layer2.2.bn1.weight\n",
      "model.visual.layer2.2.bn1.bias\n",
      "model.visual.layer2.2.conv2.weight\n",
      "model.visual.layer2.2.bn2.weight\n",
      "model.visual.layer2.2.bn2.bias\n",
      "model.visual.layer2.2.conv3.weight\n",
      "model.visual.layer2.2.bn3.weight\n",
      "model.visual.layer2.2.bn3.bias\n",
      "model.visual.layer2.3.conv1.weight\n",
      "model.visual.layer2.3.bn1.weight\n",
      "model.visual.layer2.3.bn1.bias\n",
      "model.visual.layer2.3.conv2.weight\n",
      "model.visual.layer2.3.bn2.weight\n",
      "model.visual.layer2.3.bn2.bias\n",
      "model.visual.layer2.3.conv3.weight\n",
      "model.visual.layer2.3.bn3.weight\n",
      "model.visual.layer2.3.bn3.bias\n",
      "model.visual.layer3.0.conv1.weight\n",
      "model.visual.layer3.0.bn1.weight\n",
      "model.visual.layer3.0.bn1.bias\n",
      "model.visual.layer3.0.conv2.weight\n",
      "model.visual.layer3.0.bn2.weight\n",
      "model.visual.layer3.0.bn2.bias\n",
      "model.visual.layer3.0.conv3.weight\n",
      "model.visual.layer3.0.bn3.weight\n",
      "model.visual.layer3.0.bn3.bias\n",
      "model.visual.layer3.0.downsample.0.weight\n",
      "model.visual.layer3.0.downsample.1.weight\n",
      "model.visual.layer3.0.downsample.1.bias\n",
      "model.visual.layer3.1.conv1.weight\n",
      "model.visual.layer3.1.bn1.weight\n",
      "model.visual.layer3.1.bn1.bias\n",
      "model.visual.layer3.1.conv2.weight\n",
      "model.visual.layer3.1.bn2.weight\n",
      "model.visual.layer3.1.bn2.bias\n",
      "model.visual.layer3.1.conv3.weight\n",
      "model.visual.layer3.1.bn3.weight\n",
      "model.visual.layer3.1.bn3.bias\n",
      "model.visual.layer3.2.conv1.weight\n",
      "model.visual.layer3.2.bn1.weight\n",
      "model.visual.layer3.2.bn1.bias\n",
      "model.visual.layer3.2.conv2.weight\n",
      "model.visual.layer3.2.bn2.weight\n",
      "model.visual.layer3.2.bn2.bias\n",
      "model.visual.layer3.2.conv3.weight\n",
      "model.visual.layer3.2.bn3.weight\n",
      "model.visual.layer3.2.bn3.bias\n",
      "model.visual.layer3.3.conv1.weight\n",
      "model.visual.layer3.3.bn1.weight\n",
      "model.visual.layer3.3.bn1.bias\n",
      "model.visual.layer3.3.conv2.weight\n",
      "model.visual.layer3.3.bn2.weight\n",
      "model.visual.layer3.3.bn2.bias\n",
      "model.visual.layer3.3.conv3.weight\n",
      "model.visual.layer3.3.bn3.weight\n",
      "model.visual.layer3.3.bn3.bias\n",
      "model.visual.layer3.4.conv1.weight\n",
      "model.visual.layer3.4.bn1.weight\n",
      "model.visual.layer3.4.bn1.bias\n",
      "model.visual.layer3.4.conv2.weight\n",
      "model.visual.layer3.4.bn2.weight\n",
      "model.visual.layer3.4.bn2.bias\n",
      "model.visual.layer3.4.conv3.weight\n",
      "model.visual.layer3.4.bn3.weight\n",
      "model.visual.layer3.4.bn3.bias\n",
      "model.visual.layer3.5.conv1.weight\n",
      "model.visual.layer3.5.bn1.weight\n",
      "model.visual.layer3.5.bn1.bias\n",
      "model.visual.layer3.5.conv2.weight\n",
      "model.visual.layer3.5.bn2.weight\n",
      "model.visual.layer3.5.bn2.bias\n",
      "model.visual.layer3.5.conv3.weight\n",
      "model.visual.layer3.5.bn3.weight\n",
      "model.visual.layer3.5.bn3.bias\n",
      "model.visual.layer4.0.conv1.weight\n",
      "model.visual.layer4.0.bn1.weight\n",
      "model.visual.layer4.0.bn1.bias\n",
      "model.visual.layer4.0.conv2.weight\n",
      "model.visual.layer4.0.bn2.weight\n",
      "model.visual.layer4.0.bn2.bias\n",
      "model.visual.layer4.0.conv3.weight\n",
      "model.visual.layer4.0.bn3.weight\n",
      "model.visual.layer4.0.bn3.bias\n",
      "model.visual.layer4.0.downsample.0.weight\n",
      "model.visual.layer4.0.downsample.1.weight\n",
      "model.visual.layer4.0.downsample.1.bias\n",
      "model.visual.layer4.1.conv1.weight\n",
      "model.visual.layer4.1.bn1.weight\n",
      "model.visual.layer4.1.bn1.bias\n",
      "model.visual.layer4.1.conv2.weight\n",
      "model.visual.layer4.1.bn2.weight\n",
      "model.visual.layer4.1.bn2.bias\n",
      "model.visual.layer4.1.conv3.weight\n",
      "model.visual.layer4.1.bn3.weight\n",
      "model.visual.layer4.1.bn3.bias\n",
      "model.visual.layer4.2.conv1.weight\n",
      "model.visual.layer4.2.bn1.weight\n",
      "model.visual.layer4.2.bn1.bias\n",
      "model.visual.layer4.2.conv2.weight\n",
      "model.visual.layer4.2.bn2.weight\n",
      "model.visual.layer4.2.bn2.bias\n",
      "model.visual.layer4.2.conv3.weight\n",
      "model.visual.layer4.2.bn3.weight\n",
      "model.visual.layer4.2.bn3.bias\n",
      "model.visual.attnpool.positional_embedding\n",
      "model.visual.attnpool.k_proj.weight\n",
      "model.visual.attnpool.k_proj.bias\n",
      "model.visual.attnpool.q_proj.weight\n",
      "model.visual.attnpool.q_proj.bias\n",
      "model.visual.attnpool.v_proj.weight\n",
      "model.visual.attnpool.v_proj.bias\n",
      "model.visual.attnpool.c_proj.weight\n",
      "model.visual.attnpool.c_proj.bias\n",
      "model.transformer.resblocks.0.attn.in_proj_weight\n",
      "model.transformer.resblocks.0.attn.in_proj_bias\n",
      "model.transformer.resblocks.0.attn.out_proj.weight\n",
      "model.transformer.resblocks.0.attn.out_proj.bias\n",
      "model.transformer.resblocks.0.ln_1.weight\n",
      "model.transformer.resblocks.0.ln_1.bias\n",
      "model.transformer.resblocks.0.mlp.c_fc.weight\n",
      "model.transformer.resblocks.0.mlp.c_fc.bias\n",
      "model.transformer.resblocks.0.mlp.c_proj.weight\n",
      "model.transformer.resblocks.0.mlp.c_proj.bias\n",
      "model.transformer.resblocks.0.ln_2.weight\n",
      "model.transformer.resblocks.0.ln_2.bias\n",
      "model.transformer.resblocks.1.attn.in_proj_weight\n",
      "model.transformer.resblocks.1.attn.in_proj_bias\n",
      "model.transformer.resblocks.1.attn.out_proj.weight\n",
      "model.transformer.resblocks.1.attn.out_proj.bias\n",
      "model.transformer.resblocks.1.ln_1.weight\n",
      "model.transformer.resblocks.1.ln_1.bias\n",
      "model.transformer.resblocks.1.mlp.c_fc.weight\n",
      "model.transformer.resblocks.1.mlp.c_fc.bias\n",
      "model.transformer.resblocks.1.mlp.c_proj.weight\n",
      "model.transformer.resblocks.1.mlp.c_proj.bias\n",
      "model.transformer.resblocks.1.ln_2.weight\n",
      "model.transformer.resblocks.1.ln_2.bias\n",
      "model.transformer.resblocks.2.attn.in_proj_weight\n",
      "model.transformer.resblocks.2.attn.in_proj_bias\n",
      "model.transformer.resblocks.2.attn.out_proj.weight\n",
      "model.transformer.resblocks.2.attn.out_proj.bias\n",
      "model.transformer.resblocks.2.ln_1.weight\n",
      "model.transformer.resblocks.2.ln_1.bias\n",
      "model.transformer.resblocks.2.mlp.c_fc.weight\n",
      "model.transformer.resblocks.2.mlp.c_fc.bias\n",
      "model.transformer.resblocks.2.mlp.c_proj.weight\n",
      "model.transformer.resblocks.2.mlp.c_proj.bias\n",
      "model.transformer.resblocks.2.ln_2.weight\n",
      "model.transformer.resblocks.2.ln_2.bias\n",
      "model.transformer.resblocks.3.attn.in_proj_weight\n",
      "model.transformer.resblocks.3.attn.in_proj_bias\n",
      "model.transformer.resblocks.3.attn.out_proj.weight\n",
      "model.transformer.resblocks.3.attn.out_proj.bias\n",
      "model.transformer.resblocks.3.ln_1.weight\n",
      "model.transformer.resblocks.3.ln_1.bias\n",
      "model.transformer.resblocks.3.mlp.c_fc.weight\n",
      "model.transformer.resblocks.3.mlp.c_fc.bias\n",
      "model.transformer.resblocks.3.mlp.c_proj.weight\n",
      "model.transformer.resblocks.3.mlp.c_proj.bias\n",
      "model.transformer.resblocks.3.ln_2.weight\n",
      "model.transformer.resblocks.3.ln_2.bias\n",
      "model.transformer.resblocks.4.attn.in_proj_weight\n",
      "model.transformer.resblocks.4.attn.in_proj_bias\n",
      "model.transformer.resblocks.4.attn.out_proj.weight\n",
      "model.transformer.resblocks.4.attn.out_proj.bias\n",
      "model.transformer.resblocks.4.ln_1.weight\n",
      "model.transformer.resblocks.4.ln_1.bias\n",
      "model.transformer.resblocks.4.mlp.c_fc.weight\n",
      "model.transformer.resblocks.4.mlp.c_fc.bias\n",
      "model.transformer.resblocks.4.mlp.c_proj.weight\n",
      "model.transformer.resblocks.4.mlp.c_proj.bias\n",
      "model.transformer.resblocks.4.ln_2.weight\n",
      "model.transformer.resblocks.4.ln_2.bias\n",
      "model.transformer.resblocks.5.attn.in_proj_weight\n",
      "model.transformer.resblocks.5.attn.in_proj_bias\n",
      "model.transformer.resblocks.5.attn.out_proj.weight\n",
      "model.transformer.resblocks.5.attn.out_proj.bias\n",
      "model.transformer.resblocks.5.ln_1.weight\n",
      "model.transformer.resblocks.5.ln_1.bias\n",
      "model.transformer.resblocks.5.mlp.c_fc.weight\n",
      "model.transformer.resblocks.5.mlp.c_fc.bias\n",
      "model.transformer.resblocks.5.mlp.c_proj.weight\n",
      "model.transformer.resblocks.5.mlp.c_proj.bias\n",
      "model.transformer.resblocks.5.ln_2.weight\n",
      "model.transformer.resblocks.5.ln_2.bias\n",
      "model.transformer.resblocks.6.attn.in_proj_weight\n",
      "model.transformer.resblocks.6.attn.in_proj_bias\n",
      "model.transformer.resblocks.6.attn.out_proj.weight\n",
      "model.transformer.resblocks.6.attn.out_proj.bias\n",
      "model.transformer.resblocks.6.ln_1.weight\n",
      "model.transformer.resblocks.6.ln_1.bias\n",
      "model.transformer.resblocks.6.mlp.c_fc.weight\n",
      "model.transformer.resblocks.6.mlp.c_fc.bias\n",
      "model.transformer.resblocks.6.mlp.c_proj.weight\n",
      "model.transformer.resblocks.6.mlp.c_proj.bias\n",
      "model.transformer.resblocks.6.ln_2.weight\n",
      "model.transformer.resblocks.6.ln_2.bias\n",
      "model.transformer.resblocks.7.attn.in_proj_weight\n",
      "model.transformer.resblocks.7.attn.in_proj_bias\n",
      "model.transformer.resblocks.7.attn.out_proj.weight\n",
      "model.transformer.resblocks.7.attn.out_proj.bias\n",
      "model.transformer.resblocks.7.ln_1.weight\n",
      "model.transformer.resblocks.7.ln_1.bias\n",
      "model.transformer.resblocks.7.mlp.c_fc.weight\n",
      "model.transformer.resblocks.7.mlp.c_fc.bias\n",
      "model.transformer.resblocks.7.mlp.c_proj.weight\n",
      "model.transformer.resblocks.7.mlp.c_proj.bias\n",
      "model.transformer.resblocks.7.ln_2.weight\n",
      "model.transformer.resblocks.7.ln_2.bias\n",
      "model.transformer.resblocks.8.attn.in_proj_weight\n",
      "model.transformer.resblocks.8.attn.in_proj_bias\n",
      "model.transformer.resblocks.8.attn.out_proj.weight\n",
      "model.transformer.resblocks.8.attn.out_proj.bias\n",
      "model.transformer.resblocks.8.ln_1.weight\n",
      "model.transformer.resblocks.8.ln_1.bias\n",
      "model.transformer.resblocks.8.mlp.c_fc.weight\n",
      "model.transformer.resblocks.8.mlp.c_fc.bias\n",
      "model.transformer.resblocks.8.mlp.c_proj.weight\n",
      "model.transformer.resblocks.8.mlp.c_proj.bias\n",
      "model.transformer.resblocks.8.ln_2.weight\n",
      "model.transformer.resblocks.8.ln_2.bias\n",
      "model.transformer.resblocks.9.attn.in_proj_weight\n",
      "model.transformer.resblocks.9.attn.in_proj_bias\n",
      "model.transformer.resblocks.9.attn.out_proj.weight\n",
      "model.transformer.resblocks.9.attn.out_proj.bias\n",
      "model.transformer.resblocks.9.ln_1.weight\n",
      "model.transformer.resblocks.9.ln_1.bias\n",
      "model.transformer.resblocks.9.mlp.c_fc.weight\n",
      "model.transformer.resblocks.9.mlp.c_fc.bias\n",
      "model.transformer.resblocks.9.mlp.c_proj.weight\n",
      "model.transformer.resblocks.9.mlp.c_proj.bias\n",
      "model.transformer.resblocks.9.ln_2.weight\n",
      "model.transformer.resblocks.9.ln_2.bias\n",
      "model.transformer.resblocks.10.attn.in_proj_weight\n",
      "model.transformer.resblocks.10.attn.in_proj_bias\n",
      "model.transformer.resblocks.10.attn.out_proj.weight\n",
      "model.transformer.resblocks.10.attn.out_proj.bias\n",
      "model.transformer.resblocks.10.ln_1.weight\n",
      "model.transformer.resblocks.10.ln_1.bias\n",
      "model.transformer.resblocks.10.mlp.c_fc.weight\n",
      "model.transformer.resblocks.10.mlp.c_fc.bias\n",
      "model.transformer.resblocks.10.mlp.c_proj.weight\n",
      "model.transformer.resblocks.10.mlp.c_proj.bias\n",
      "model.transformer.resblocks.10.ln_2.weight\n",
      "model.transformer.resblocks.10.ln_2.bias\n",
      "model.transformer.resblocks.11.attn.in_proj_weight\n",
      "model.transformer.resblocks.11.attn.in_proj_bias\n",
      "model.transformer.resblocks.11.attn.out_proj.weight\n",
      "model.transformer.resblocks.11.attn.out_proj.bias\n",
      "model.transformer.resblocks.11.ln_1.weight\n",
      "model.transformer.resblocks.11.ln_1.bias\n",
      "model.transformer.resblocks.11.mlp.c_fc.weight\n",
      "model.transformer.resblocks.11.mlp.c_fc.bias\n",
      "model.transformer.resblocks.11.mlp.c_proj.weight\n",
      "model.transformer.resblocks.11.mlp.c_proj.bias\n",
      "model.transformer.resblocks.11.ln_2.weight\n",
      "model.transformer.resblocks.11.ln_2.bias\n",
      "model.token_embedding.weight\n",
      "model.ln_final.weight\n",
      "model.ln_final.bias\n",
      "v_proj.weight\n",
      "v_proj.bias\n",
      "c_proj.weight\n",
      "c_proj.bias\n",
      "final_conv.weight\n",
      "final_conv.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in clip_res.named_parameters():\n",
    "    print(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
